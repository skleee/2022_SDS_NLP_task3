{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8VR8kd4ipPN"
      },
      "source": [
        "# KoBART fine-tuning ÌååÏù¥Ïç¨ÎÖ∏Ìä∏Î∂Å Î≤ÑÏ†ÑÏûÖÎãàÎã§."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "train.json, test.jsonÏù¥ Ìè¨Ìï®Îêú `data/` Ìè¥ÎçîÏôÄ Í∞ôÏùÄ Î†àÎ≤®Ïóê ÏûàÎã§Í≥† Í∞ÄÏ†ïÌï©ÎãàÎã§.\n",
        "\n",
        "   ‚îú main_trainer.ipynb<br>\n",
        ".. ‚îî data<br>\n",
        ".... ‚îú train.json<br>\n",
        ".... ‚îú test.json<br>\n",
        ".... ‚îî sample_submission.csv<br>"
      ],
      "metadata": {
        "id": "uBQoX_uyrJrk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfUrYcjmiRNg",
        "outputId": "61b9dd59-d57c-4f80-e721-3fa80c7d6ff3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# git cloneÏùÑ ÌÜµÌï¥ Í∞ÄÏ†∏Ïò® 2022_SDS_NLP_task3 Ìè¥Îçî ÎÇ¥Ïóê ÏúÑÏπòÌïòÎèÑÎ°ù Í≤ΩÎ°úÎ•º Ïù¥ÎèôÌï©ÎãàÎã§.\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/2022_SDS_NLP_task3')  # Í≤ΩÎ°úÏóê ÎßûÍ≤å ÏàòÏ†ïÌï¥Ï£ºÏÑ∏Ïöî"
      ],
      "metadata": {
        "id": "9CaVs09Ej_R8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUbndtirkBY9",
        "outputId": "470e6be7-aeee-47ea-d19a-fb7bfa979ffa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.Data_EDA.ipynb   data\t\t       main_trainer.py\tutils.py\n",
            "2.Tokenizer.ipynb  logs\t\t       README.md\n",
            "3.Inference.ipynb  main_trainer.ipynb  results\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_gaaojSBoQ5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "589dfa4e-5dee-4236-8c8b-543361f876e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.22.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.9.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.5.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.12.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.9.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.8.2)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.1.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.6.15)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.97)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.7/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.2.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from rouge_score) (3.7)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk->rouge_score) (4.64.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->rouge_score) (7.1.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk->rouge_score) (2022.6.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->rouge_score) (1.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (0.8.10)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: asian-bart in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from asian-bart) (1.12.1+cu113)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from asian-bart) (0.1.97)\n",
            "Requirement already satisfied: transformers>=4 in /usr/local/lib/python3.7/dist-packages (from asian-bart) (4.22.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers>=4->asian-bart) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers>=4->asian-bart) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4->asian-bart) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4->asian-bart) (3.8.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4->asian-bart) (0.9.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=4->asian-bart) (4.12.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=4->asian-bart) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=4->asian-bart) (1.21.6)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=4->asian-bart) (0.12.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=4->asian-bart) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers>=4->asian-bart) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers>=4->asian-bart) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=4->asian-bart) (3.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4->asian-bart) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4->asian-bart) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4->asian-bart) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4->asian-bart) (3.0.4)\n"
          ]
        }
      ],
      "source": [
        "! pip install transformers\n",
        "! pip install datasets\n",
        "! pip install sentencepiece\n",
        "! pip install rouge_score\n",
        "! pip install tabulate\n",
        "! pip install asian-bart"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHlRNvK1frHH"
      },
      "source": [
        "## ÌïÑÏöîÌïú ÎùºÏù¥Î∏åÎü¨Î¶¨, Ìå®ÌÇ§ÏßÄ ÏûÑÌè¨Ìä∏"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rimUDCQGoTAJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "import nltk\n",
        "import random\n",
        "import datasets\n",
        "import argparse\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "\n",
        "from transformers import (\n",
        "    Seq2SeqTrainingArguments,\n",
        "    Seq2SeqTrainer,\n",
        "    DataCollatorForSeq2Seq,\n",
        "    BartForConditionalGeneration, \n",
        "    PreTrainedTokenizerFast\n",
        ") \n",
        "from tqdm import tqdm\n",
        "\n",
        "from IPython import embed\n",
        "from time import strftime\n",
        "from tabulate import tabulate\n",
        "\n",
        "\n",
        "# Îç∞Ïù¥ÌÑ∞ÏÖã Í¥ÄÎ†® Ìå®ÌÇ§ÏßÄ\n",
        "import pyarrow as pa\n",
        "import pyarrow.dataset as ds\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "# from torch.utils.data import Dataset\n",
        "\n",
        "import os\n",
        "\n",
        "\n",
        "os.environ['WANDB_DISABLED'] = 'true'\n",
        "\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(0)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDQoYrz9frHI"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed: int):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed) # Multi GPU\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.enabled = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJO4TovGfrHJ"
      },
      "source": [
        "## ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ ÏÑ§Ï†ï"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lglyAqo2frHJ"
      },
      "outputs": [],
      "source": [
        "seed = 42\n",
        "\n",
        "model_backbone = 'kobart_base'\n",
        "model_pretrained = 'gogamza/kobart-base-v2'\n",
        "data_dir =  'data'\n",
        "output_dir = 'checkpoint'\n",
        "result_dir = 'results'\n",
        "\n",
        "lr = 1e-5\n",
        "wr = 0.0\n",
        "wd = 0.01\n",
        "\n",
        "train_batch_size = 16\n",
        "test_batch_size = 4\n",
        "num_train_epochs = 10\n",
        "encoder_max_length = 512\n",
        "decoder_max_length = 64\n",
        "label_smoothing = 0.0\n",
        "\n",
        "stratify = True\n",
        "test_size = 0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_WqAg9efrHK"
      },
      "outputs": [],
      "source": [
        "set_seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOFGjG4WfrHK"
      },
      "source": [
        "## Î°úÍ∑∏ Ìè¥Îçî ÏÑ§Ï†ï"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7cZQZbPfrHK"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "0. Set log dir\n",
        "'''\n",
        "log_dir = os.path.join(result_dir, model_backbone)\n",
        "\n",
        "if not os.path.exists(log_dir):\n",
        "    os.makedirs(log_dir)\n",
        "\n",
        "log_dirs = os.listdir(log_dir)\n",
        "\n",
        "if len(log_dirs) == 0:\n",
        "    idx = 0\n",
        "else:\n",
        "    idx_list = sorted([int(d.split('_')[0]) for d in log_dirs])\n",
        "    idx = idx_list[-1] + 1\n",
        "\n",
        "cur_log_dir = '%d_%s' % (idx, strftime('%Y%m%d-%H%M'))\n",
        "full_log_dir = os.path.join(log_dir, cur_log_dir)\n",
        "\n",
        "if not os.path.exists(full_log_dir):\n",
        "    os.mkdir(full_log_dir)\n",
        "\n",
        "output_dir = os.path.join(full_log_dir, output_dir)\n",
        "\n",
        "final_result = {}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioBCSmk0frHL"
      },
      "source": [
        "## Î™®Îç∏, ÌÜ†ÌÅ¨ÎÇòÏù¥Ï†Ä Î°úÎìú"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGtlNKAgfrHL",
        "outputId": "5fa37f55-fff6-4503-bbfa-12db5a239575"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BartConfig {\n",
            "  \"_name_or_path\": \"gogamza/kobart-base-v2\",\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": false,\n",
            "  \"architectures\": [\n",
            "    \"BartModel\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
            "  \"bos_token_id\": 1,\n",
            "  \"classif_dropout\": 0.1,\n",
            "  \"classifier_dropout\": 0.1,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 3072,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 1,\n",
            "  \"do_blenderbot_90_layernorm\": false,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 3072,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 6,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"extra_pos_embeddings\": 2,\n",
            "  \"force_bos_token_to_be_generated\": false,\n",
            "  \"forced_eos_token_id\": 1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEGATIVE\",\n",
            "    \"1\": \"POSITIVE\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"kobart_version\": 2.0,\n",
            "  \"label2id\": {\n",
            "    \"NEGATIVE\": 0,\n",
            "    \"POSITIVE\": 1\n",
            "  },\n",
            "  \"max_position_embeddings\": 1026,\n",
            "  \"model_type\": \"bart\",\n",
            "  \"normalize_before\": false,\n",
            "  \"normalize_embedding\": true,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 3,\n",
            "  \"scale_embedding\": false,\n",
            "  \"static_position_embeddings\": false,\n",
            "  \"tokenizer_class\": \"PreTrainedTokenizerFast\",\n",
            "  \"transformers_version\": \"4.22.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30000\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download model and tokenizer\n",
        "\n",
        "if model_pretrained == 'kykim/bertshared-kor-base':\n",
        "    from transformers import BertTokenizerFast, EncoderDecoderModel\n",
        "    tokenizer = BertTokenizerFast.from_pretrained(\"kykim/bertshared-kor-base\", model_max_length=512)\n",
        "    model = EncoderDecoderModel.from_pretrained(\"kykim/bertshared-kor-base\")\n",
        "    \n",
        "    model.config.min_length = None\n",
        "    model.config.decoder_start_token_id = tokenizer.cls_token_id\n",
        "    model.config.pad_token_id = tokenizer.pad_token_id\n",
        "    model.config.vocab_size = model.config.decoder.vocab_size\n",
        "    \n",
        "\n",
        "elif model_pretrained == 'hyunwoongko/asian-bart-ecjk':\n",
        "    # ÎùºÏù¥Î∏åÎü¨Î¶¨ ÏÑ§ÏπòÍ∞Ä ÌïÑÏöîÌï©ÎãàÎã§. (pip install asian-bart)\n",
        "    from asian_bart import AsianBartTokenizer, AsianBartForConditionalGeneration\n",
        "    tokenizer = AsianBartTokenizer.from_pretrained(\"hyunwoongko/asian-bart-ecjk\")\n",
        "    model = AsianBartForConditionalGeneration.from_pretrained(\"hyunwoongko/asian-bart-ecjk\")\n",
        "\n",
        "elif model_pretrained == 'paust/pko-t5-base':\n",
        "    from transformers import T5TokenizerFast, T5ForConditionalGeneration\n",
        "    tokenizer = T5TokenizerFast.from_pretrained('paust/pko-t5-base')\n",
        "    model = T5ForConditionalGeneration.from_pretrained('paust/pko-t5-base')\n",
        "\n",
        "elif model_pretrained == 'facebook/mbart-large-50':\n",
        "    from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
        "    model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50\")\n",
        "    tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50\", src_lang=\"ko_KR\", tgt_lang=\"ko_KR\")\n",
        "\n",
        "elif model_pretrained in ['gogamza/kobart-base-v1', 'cosmoquester/bart-ko-mini', 'gogamza/kobart-summarization', 'gogamza/kobart-base-v2']:\n",
        "    tokenizer = PreTrainedTokenizerFast.from_pretrained(model_pretrained)\n",
        "    # Default pre-trained model is from https://github.com/seujung/KoBART-summarization \n",
        "    model = BartForConditionalGeneration.from_pretrained(model_pretrained)\n",
        "\n",
        "else:\n",
        "    print(f\"Model {model_pretrained} is not supported\")\n",
        "    exit()\n",
        "\n",
        "print(model.config)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yD2_hzYbfrHM"
      },
      "source": [
        "## 2. Îç∞Ïù¥ÌÑ∞ÏÖã Î°úÎìú"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-o-c4XxfrHM",
        "outputId": "c5975e0a-f63a-4407-a563-7f6222faba3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163,
          "referenced_widgets": [
            "d3640eda68d54a168d6a31027ee44768",
            "52a6b7e54b6e4891b5cfa47ea1e7308e",
            "f96370c72aa84400a0456f2ac81698e4",
            "0ed62bec5c144035b905be94a8f5d3da",
            "b5d0719e86b14edb8830a53e232ecce2",
            "7f2f0ab591064800b6c24a503c1c7b9c",
            "b368dfc422804fd3a3917f8221660d2c",
            "49a641b102914a759f96cb7cbe46bb79",
            "66c28bbc85cc4015a75e85dc3712bdcf",
            "dec16cdf0a8140d2b6f04906a7a9af15",
            "f584d826a168464aa1d47c9b5dbea71b",
            "5ab60cfd4b2a426f82c893be1a815203",
            "0483d7b3b90d45e88ac707a924dbd170",
            "9f366acaff344c80ab586613da27f6d2",
            "e070ed9f13904c0fb53a4b1dbac3f321",
            "f569bebd37134707a6e10ce0b64f1649",
            "364edffa798a4b9a971cd06f14509192",
            "845555896f0e43958f33f38149186916",
            "efe1a7b1ffca4c7e844d6f18e472ce60",
            "b98ac0bf3df64b94a3f695c70d03339e",
            "c70e564e7ddc4e1181a128e150a5a739",
            "a2b55de46eee4200952b026d35d46e61",
            "a98af225353c48a8b43205064aea3234",
            "a1deb16caf5244118a3f9df48f23a6e2",
            "c84c93495f274eb093980a02bb57d7e1",
            "9821a46e202d4bbda0e600cde6c159c2",
            "a9ea1107dbf84d82aef30ec37d093ff1",
            "f2ff567d035c442abe226f3814b695e0",
            "9933d8b8b6684b18b70798d9bfaf6c2e",
            "8994d7f332684213b67b6abad31b5a51",
            "5f9f9ac49f9e4898b876ae53c0fe01fb",
            "368e41f4be0948d98e97f00cad1cad4f",
            "85a547eaffd049df81b587ba9cc4cb59",
            "0f8a2d72d83245feb9092cef980e21a6",
            "1e444421e291499090646c32eb11b5d7",
            "f02387bad44745d09e8407d85edb9c59",
            "820dcb1d25dd43fcba7dfc39c025a8a2",
            "6b517637c8574946b8588df827deb556",
            "4159fe7e3c1941629fa1a1a1531ae09f",
            "82c97943fce749d9be041f9578c15354",
            "57909452e375416a9b0bb8ee5da71134",
            "4811f98ed07942b19c0dbfd4c0189d3c",
            "26622b46bde047e8892da9105baac32b",
            "7ac7202754db4e8388581ace19c9cb9a"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Loading data from data\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Casting to class labels:   0%|          | 0/3 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d3640eda68d54a168d6a31027ee44768"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Casting the dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ab60cfd4b2a426f82c893be1a815203"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Casting to class labels:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a98af225353c48a8b43205064aea3234"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Casting the dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f8a2d72d83245feb9092cef980e21a6"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "print(f\"> Loading data from {data_dir}\")\n",
        "TRAIN_SOURCE = os.path.join(data_dir, \"train.json\")\n",
        "TEST_SOURCE = os.path.join(data_dir, \"test.json\")\n",
        "\n",
        "with open(TRAIN_SOURCE) as f:\n",
        "    TRAIN_DATA = json.loads(f.read())\n",
        "    \n",
        "with open(TEST_SOURCE) as f:\n",
        "    TEST_DATA = json.loads(f.read())\n",
        "\n",
        "train = pd.DataFrame(columns=['uid', 'title', 'region', 'context', 'summary'])\n",
        "uid = 1000\n",
        "for data in TRAIN_DATA:\n",
        "    for agenda in data['context'].keys():\n",
        "        context = ''\n",
        "        for line in data['context'][agenda]:\n",
        "            context += data['context'][agenda][line]\n",
        "            context += ' '\n",
        "        train.loc[uid, 'uid'] = uid\n",
        "        train.loc[uid, 'title'] = data['title']\n",
        "        train.loc[uid, 'region'] = data['region']\n",
        "        train.loc[uid, 'context'] = context[:-1]\n",
        "        train.loc[uid, 'summary'] = data['label'][agenda]['summary']\n",
        "        uid += 1\n",
        "\n",
        "test = pd.DataFrame(columns=['uid', 'title', 'region', 'context'])\n",
        "uid = 2000\n",
        "for data in TEST_DATA:\n",
        "    for agenda in data['context'].keys():\n",
        "        context = ''\n",
        "        for line in data['context'][agenda]:\n",
        "            context += data['context'][agenda][line]\n",
        "            context += ' '\n",
        "        test.loc[uid, 'uid'] = uid\n",
        "        test.loc[uid, 'title'] = data['title']\n",
        "        test.loc[uid, 'region'] = data['region']\n",
        "        test.loc[uid, 'context'] = context[:-1]\n",
        "        uid += 1\n",
        "\n",
        "if stratify:\n",
        "    # https://dacon.io/competitions/official/235813/codeshare/3719?page=1&dtype=recent Ï∞∏Í≥†\n",
        "    # context ÌÜ†ÌÅ∞ Í∏∏Ïù¥ \n",
        "    def token_len(text):\n",
        "        return len(tokenizer.tokenize(text))\n",
        "\n",
        "    # contextÏùò ÎÇ¥Ïö©ÏùÑ ÏïàÍ±¥ ÏÉÅÏ†ï, ÏùòÏõê Î∞úÏñ∏ ÏöîÏïΩ, Î∂ÄÏÑú Î≥¥Í≥†, Í∏∞ÌÉÄÎ°ú Îü¨ÌîÑÌïòÍ≤å Î∂ÑÎ•ò\n",
        "    def type_classifier(context):\n",
        "        if 'Î≥¥ÏûÑ' in context[:1000]:\n",
        "            return 'ÏùòÏõê Î≥¥ÏûÑ'\n",
        "        elif (len(context.split('ÏùòÏõêÎãò Ïßà')) > 2 and len(tokenizer.tokenize(context)) > 1024 and 'ÏÉÅÏ†ï' not in context[:200]):#and 'Î≥¥Í≥†' not in summary[-3:]:\n",
        "            return 'ÏùòÏõê Î∞úÏñ∏ ÏöîÏïΩ' \n",
        "        elif 'ÏûêÏú†Î∞úÏñ∏' in context[:200] and len(context.split('ÏùòÏõêÎãò ÎÇò')) > 1:\n",
        "            return 'ÏûêÏú†Î∞úÏñ∏'\n",
        "        elif 'ÏÉÅÏ†ï' in context[:200]:\n",
        "            return 'ÏïàÍ±¥ ÏÉÅÏ†ï'\n",
        "        elif 'Í∞úÏùò' in context[:100]:\n",
        "            return 'Í∞úÏùò ÏÑ†Ìè¨'\n",
        "        elif 'Î≥¥Í≥†' in context[:200]:\n",
        "            return 'Î∂ÄÏÑú Î≥¥Í≥†'\n",
        "        else:\n",
        "            return 'Í∏∞ÌÉÄ' \n",
        "\n",
        "    # train,testÏóê Î≥∏Î¨∏ ÌÜ†ÌÅ∞ Í∏∏Ïù¥ÏôÄ Îü¨ÌîÑÌïú ÎÇ¥Ïö© Î∂ÑÎ•ò Ï∂îÍ∞Ä\n",
        "    train['con_token_len'] = train['context'].apply(token_len)\n",
        "    train['con_type'] = train['context'].apply(type_classifier)\n",
        "\n",
        "    test['con_token_len'] = test['context'].apply(token_len)\n",
        "    test['con_type'] = test['context'].apply(type_classifier)\n",
        "\n",
        "    # convert to Huggingface dataset\n",
        "    train = train[['context', 'summary', 'con_type']]\n",
        "    test = test[['context', 'con_type']]\n",
        "\n",
        "    train_dataset = Dataset(pa.Table.from_pandas(train))\n",
        "    test_dataset = Dataset(pa.Table.from_pandas(test))\n",
        "\n",
        "    train_dataset = train_dataset.class_encode_column(\"con_type\")\n",
        "    test_dataset = test_dataset.class_encode_column(\"con_type\")\n",
        "    \n",
        "    try:\n",
        "        train_dataset = train_dataset.remove_columns('__index_level_0__')\n",
        "        test_dataset = test_dataset.remove_columns('__index_level_0__')\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    train_data, eval_data = train_dataset.train_test_split(test_size=test_size, shuffle=True, seed=seed, stratify_by_column='con_type').values()\n",
        "\n",
        "else:\n",
        "    # convert to Huggingface dataset\n",
        "    train = train[['context', 'summary']]\n",
        "    test = test[['context']]\n",
        "\n",
        "    train_dataset = Dataset(pa.Table.from_pandas(train))\n",
        "    test_dataset = Dataset(pa.Table.from_pandas(test))\n",
        "\n",
        "    try:\n",
        "        train_dataset = train_dataset.remove_columns('__index_level_0__')\n",
        "        test_dataset = test_dataset.remove_columns('__index_level_0__')\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    train_data, eval_data = train_dataset.train_test_split(test_size=test_size, shuffle=True, seed=seed).values()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tC7qIpyQfrHN",
        "outputId": "e579f9eb-af96-413d-e11f-f4024eb9f0b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Number of train data: 2395, eval data: 599, test data: 506\n"
          ]
        }
      ],
      "source": [
        "train_data, eval_data, test_data = train_data, eval_data, test_dataset\n",
        "print(f'> Number of train data: {len(train_data)}, eval data: {len(eval_data)}, test data: {len(test_data)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5WxTLUZSfrHN"
      },
      "outputs": [],
      "source": [
        "# Preprocess and tokenize data\n",
        "def batch_tokenize_preprocess(batch, tokenizer, max_source_length, max_target_length):\n",
        "    source, target = batch[\"context\"], batch[\"summary\"]\n",
        "    source_tokenized = tokenizer(\n",
        "        source, padding=\"max_length\", truncation=True, max_length=max_source_length\n",
        "    )\n",
        "    target_tokenized = tokenizer(\n",
        "        target, padding=\"max_length\", truncation=True, max_length=max_target_length\n",
        "    )\n",
        "\n",
        "    batch = {k: v for k, v in source_tokenized.items()}\n",
        "    # Ignore padding in the loss\n",
        "    batch[\"labels\"] = [\n",
        "        [-100 if token == tokenizer.pad_token_id else token for token in l]\n",
        "        for l in target_tokenized[\"input_ids\"]\n",
        "    ]\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWoUXwkkfrHN",
        "outputId": "a33715f7-0f04-493d-8427-57a448163fa4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "d41d73172ea84ef09fd73345bfe1cef8",
            "80c8125faa264b49b042ca8891ccbce6",
            "149eeaa6c5d24aeba7da3870a98866a0",
            "6b7109e541aa4e08968c099585c40575",
            "1e6872b3a3d349a6bf7b3b0ae1ff8686",
            "ec2125ba9608464e9d13845632ae5af4",
            "50170699516340949752872b99f50ace",
            "880ef26cb21845edb33451899b734fc8",
            "a835a16c0b744e1fb1082d0137a3eaf0",
            "aa9d6d3334024560884c6dffa6193a1d",
            "0c2cd9e7fe0a4b14b03647f0f429c6c3",
            "59286d9fc92644a38dfe859d41d9109a",
            "b4157d95c8b041ed8dda4418d48ee3c5",
            "7f2a068f77d9454c9ddd6cf3ed8db907",
            "fb37aa3850dd4f8483e32fd6d1664c9d",
            "072da68506984e0da702264fc9c019f1",
            "917cf168a3b34d7993d1075fa323cb25",
            "ecbd69e3e95747dcb2c7660764875127",
            "8e3dfef5aaaa476ebd002ad75db8765a",
            "dca704e1ddb64e94a532d46585dd0075",
            "321b1789028d4afc8c50012184bb670e",
            "043e7e881ae54540921654a61fde4bcf"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d41d73172ea84ef09fd73345bfe1cef8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "59286d9fc92644a38dfe859d41d9109a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "train_data = train_data.map(\n",
        "    lambda batch: batch_tokenize_preprocess(\n",
        "        batch, tokenizer, encoder_max_length, decoder_max_length\n",
        "    ),\n",
        "    batched=True,\n",
        "    remove_columns=train_data.column_names,\n",
        ")\n",
        "\n",
        "validation_data = eval_data.map(\n",
        "    lambda batch: batch_tokenize_preprocess(\n",
        "        batch, tokenizer, encoder_max_length, decoder_max_length\n",
        "    ),\n",
        "    batched=True,\n",
        "    remove_columns=eval_data.column_names,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNkb4wwbfrHO"
      },
      "source": [
        "## 2. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZpRKt5mfrHO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "edc5b44a2f5b455a9aebb020f1c8be74",
            "707cab4823b543b7b0bc054e506b31ea",
            "a1ee30fd88224f4d95d24a762c9bface",
            "7bd79da3c1c6490d865e573a27852a9f",
            "713c983339ca4253b30a80e8a29517dd",
            "b4db5e9c07fe4162a04e9ec10a2179a8",
            "05373960af684a7aa65cbd16357a173f",
            "e81e7f052dfc4441b8cd03ff89e9acb7",
            "2390c3e9c1914834b91919f3f8183b6e",
            "d5dd92a7cb03490e80006afe6a76488b",
            "b2a57cb7ab5d403ba900773e168c8f11"
          ]
        },
        "outputId": "0cdd4755-b719-4660-9ea5-cfd391076e1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ü§ó Evaluate: https://huggingface.co/docs/evaluate\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/2.16k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "edc5b44a2f5b455a9aebb020f1c8be74"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Borrowed from https://github.com/huggingface/transformers/blob/master/examples/seq2seq/run_summarization.py\n",
        "\n",
        "nltk.download(\"punkt\", quiet=True)\n",
        "metric = datasets.load_metric(\"rouge\")\n",
        "\n",
        "def postprocess_text(preds, labels):\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [label.strip() for label in labels]\n",
        "\n",
        "    # rougeLSum expects newline after each sentence\n",
        "    preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n",
        "    labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n",
        "\n",
        "    return preds, labels\n",
        "\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "    # Replace -100 in the labels as we can't decode them.\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Some simple post-processing\n",
        "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
        "\n",
        "    result = metric.compute(\n",
        "        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n",
        "    )\n",
        "    # Extract a few results from ROUGE\n",
        "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
        "\n",
        "    prediction_lens = [\n",
        "        np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds\n",
        "    ]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    result = {k: round(v, 4) for k, v in result.items()}\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_train_epochs = 1"
      ],
      "metadata": {
        "id": "NxnpM4kolTOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMNFG1cWfrHO",
        "outputId": "a5e7a785-2b12-430b-9739-82b9698262de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        }
      ],
      "source": [
        "# Training arguments\n",
        "# Details; https://huggingface.co/docs/transformers/main_classes/trainer#transformers.Seq2SeqTrainingArguments\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    report_to=None,\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    predict_with_generate=True,\n",
        "    output_dir=output_dir,\n",
        "    num_train_epochs=num_train_epochs,  \n",
        "    per_device_train_batch_size=train_batch_size,  \n",
        "    per_device_eval_batch_size=test_batch_size,\n",
        "    learning_rate=lr,\n",
        "    weight_decay=wd,\n",
        "    label_smoothing_factor=label_smoothing,\n",
        "    logging_dir=\"logs\",\n",
        "    save_total_limit=3,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\", \n",
        "    greater_is_better=False,\n",
        "    save_strategy='epoch',\n",
        "    evaluation_strategy='epoch',\n",
        "    # metric_for_best_model=\"eval_rouge1\", \n",
        "    # greater_is_better=True,\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "\n",
        "# Details; https://huggingface.co/docs/transformers/main_classes/trainer#transformers.Seq2SeqTrainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=validation_data,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LS7u6QRDfrHO",
        "outputId": "7f635621-8ff2-4067-cbe9-b012713da9cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 599\n",
            "  Batch size = 4\n",
            "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [150/150 00:48]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Evaluate before fine-tuning\n",
        "trainer.evaluate()\n",
        "final_result.update({'before_fine_tuning': trainer.state.log_history})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDB06qmBfrHP",
        "outputId": "4afdb600-acb2-465e-b504-60a2c17c6bef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the training set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 2395\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 150\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [150/150 03:29, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "      <th>Gen Len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.982941</td>\n",
              "      <td>55.627300</td>\n",
              "      <td>34.633800</td>\n",
              "      <td>55.422200</td>\n",
              "      <td>55.361900</td>\n",
              "      <td>20.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 599\n",
            "  Batch size = 4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [150/150 04:11]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to results/kobart_base/2_20220928-0052/checkpoint/checkpoint-150\n",
            "Configuration saved in results/kobart_base/2_20220928-0052/checkpoint/checkpoint-150/config.json\n",
            "Model weights saved in results/kobart_base/2_20220928-0052/checkpoint/checkpoint-150/pytorch_model.bin\n",
            "tokenizer config file saved in results/kobart_base/2_20220928-0052/checkpoint/checkpoint-150/tokenizer_config.json\n",
            "Special tokens file saved in results/kobart_base/2_20220928-0052/checkpoint/checkpoint-150/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from results/kobart_base/2_20220928-0052/checkpoint/checkpoint-150 (score: 0.9829413294792175).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=150, training_loss=1.548307902018229, metrics={'train_runtime': 210.0421, 'train_samples_per_second': 11.402, 'train_steps_per_second': 0.714, 'total_flos': 730159408742400.0, 'train_loss': 1.548307902018229, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "# Train the model\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0G7OuwNNfrHP"
      },
      "source": [
        "## 3. Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVntKoNWfrHP",
        "outputId": "be4e2d06-3333-440f-dca7-33ac945373c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 599\n",
            "  Batch size = 4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [150/150 00:49]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.9829413294792175,\n",
              " 'eval_rouge1': 55.6273,\n",
              " 'eval_rouge2': 34.6338,\n",
              " 'eval_rougeL': 55.4222,\n",
              " 'eval_rougeLsum': 55.3619,\n",
              " 'eval_gen_len': 20.0,\n",
              " 'eval_runtime': 50.5554,\n",
              " 'eval_samples_per_second': 11.848,\n",
              " 'eval_steps_per_second': 2.967,\n",
              " 'epoch': 1.0}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "# Evaluate after fine-tuning\n",
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tY0WJPjLfrHP"
      },
      "outputs": [],
      "source": [
        "log_history = trainer.state.log_history\n",
        "\n",
        "with open(os.path.join(full_log_dir, f'model_{model_backbone}_lr_{lr}.json'), 'w') as f:\n",
        "    final_result.update(\n",
        "        {\n",
        "            'train_results': log_history,\n",
        "            'best_results': log_history[-1],\n",
        "        }\n",
        "    )\n",
        "    json.dump(final_result, f, indent=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPHabboifrHP"
      },
      "source": [
        "# 4. ÏöîÏïΩÎ¨∏ ÏÉùÏÑ± ÏòàÏãú"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tabulate import tabulate"
      ],
      "metadata": {
        "id": "fSpDYIVqqvWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Îü∞ÌÉÄÏûÑÏùÑ Ï¥àÍ∏∞Ìôî ÌïòÏßÄ ÏïäÏùÄ Í≤ΩÏö∞\n",
        "- ÌïôÏäµÎêú Î™®Îç∏Ïù¥ `model` Î≥ÄÏàòÏóê Ï†ÄÏû•ÎêòÏñ¥ ÏûàÍ∏∞ ÎïåÎ¨∏Ïóê Îã§Ïãú Î™®Îç∏ÏùÑ ÏÑ†Ïñ∏ÌïòÏßÄ ÏïäÏúºÏÖîÎèÑ Îê©ÎãàÎã§..\n",
        "- ÏïÑÎûò ÏΩîÎìúÎ•º Î∞îÎ°ú Ïã§ÌñâÌïòÏãúÎ©¥ Îê©ÎãàÎã§."
      ],
      "metadata": {
        "id": "KUp5mMnHmzyj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_summary(test_samples, model):\n",
        "    inputs = tokenizer(\n",
        "        test_samples[\"context\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=encoder_max_length,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "    input_ids = inputs.input_ids.to(model.device)\n",
        "    attention_mask = inputs.attention_mask.to(model.device)\n",
        "    outputs = model.generate(input_ids, attention_mask=attention_mask, num_beams = 8, min_length = 10, max_length = 50, no_repeat_ngram_size=2)\n",
        "    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "    return outputs, output_str"
      ],
      "metadata": {
        "id": "WlAV1w7Kn2fh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test Ìï† ÏÉòÌîå ÌÖçÏä§Ìä∏Î•º Í≥†Î¶ÖÎãàÎã§. (evaluationÏóêÏÑú ÏÑ†ÌÉùÌï¥ÏòµÎãàÎã§.)\n",
        "test_samples = eval_data.select(range(16))"
      ],
      "metadata": {
        "id": "61-sw38Hn3lI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summaries_after_tuning = generate_summary(test_samples, model)[1]"
      ],
      "metadata": {
        "id": "6X23q6t-nHKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\n",
        "    tabulate(\n",
        "        zip(\n",
        "            range(len(summaries_after_tuning)),\n",
        "            summaries_after_tuning,\n",
        "        ),\n",
        "        headers=[\"Id\", \"Summary after\"],\n",
        "    )\n",
        ")\n",
        "print(\"\\nTarget summaries:\\n\")\n",
        "print(\n",
        "    tabulate(list(enumerate(test_samples[\"summary\"])), headers=[\"Id\", \"Target summary\"])\n",
        ")\n",
        "# print(\"\\nSource documents:\\n\")\n",
        "# print(tabulate(list(enumerate(test_samples[\"context\"])), headers=[\"Id\", \"context\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seE5C35wnYe7",
        "outputId": "a3353ec8-1d78-4eaa-847a-a39e0b8e5f3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Id  Summary after\n",
            "----  -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "   0  ÏòàÏÇ∞Í≤∞ÏÇ∞ÌäπÎ≥ÑÏúÑÏõêÌöå ÏúÑÏõêÏúºÎ°úÎäî ÏµúÍ¥ÄÏãù ÏùòÏõê, ÎÇ®Í∂ÅÏú† ÏùòÏõê, ÍπÄÏö∞Ïãù ÏùòÏõêÎãò, Í≥†Ïû¨Ìòë ÏùòÏõê, ÍπÄÏÑ±Ï±Ñ ÏùòÏõê, ÏßÑÏùòÏû• ÏùòÏõê, Ïù¥Ï§ÄÍµ¨ ÏùòÏõê, Ïù¥Ï≤úÎ¥â ÏùòÏõêÏù¥ ÏÑ†ÏûÑÎê®. ÌäπÎ≥ÑÏúÑÏõêÌöå Ïö¥ÏòÅÍ∏∞Í∞ÑÏùÄ Ï†ú2Ï∞® Ï†ïÎ°Ä\n",
            "   1  ÏùåÏÑ±Íµ∞ ÏßÄÎ∞©ÏÑ∏ÏûÖÏßïÏàòÌè¨ÏÉÅÍ∏à ÏßÄÍ∏â Ï°∞Î°Ä ÏùºÎ∂ÄÍ∞úÏ†ïÏ°∞Î°ÄÏïàÏùÄ Í≤∞ÏÜê Ï≤òÎ∂ÑÎêú ÎØ∏ÏàòÏï°ÏùÑ ÏßïÏàòÌïòÏó¨ ÏÑ∏ÏûÖ Ï¶ùÎåÄÏóê Í∏∞Ïó¨Ìïú Í≥µÎ¨¥ÏõêÏóêÍ≤å Ìè¨ÏÉÅÍ∏àÏùÑ ÏßÄÍ∏âÌïòÍ≥†Ïûê Ï†úÏ†ïÎêòÏóàÏúºÎ©∞, Ìï¥Îãπ ÏïàÍ±¥ÏùÄ Í∞ÄÍ≤∞Îê®\n",
            "   2  Í∏∞ÌöçÍ∞êÏÇ¨Ïã§Ïû• Ïù¥Ïû•Ìï¥Îäî 2008ÎÖÑÎèÑ ÏÉÅÎ∞òÍ∏∞ Ï£ºÏöîÏóÖÎ¨¥ Ï∂îÏßÑÏã§Ï†ÅÍ≥º 2008ÎÖÑ ÌïòÎ∞òÍ∏∞ Ï£ºÏöî ÏóÖÎ¨¥ Ï∂îÏßÑÍ≥ÑÌöç, ÌäπÏàòÏãúÏ±Ö ÏàúÏúºÎ°ú Î≥¥Í≥†Ìï† Í≤É. <Ìëú 1ÌéòÏù¥ÏßÄÍ∞Ä ÎêòÍ≤†ÏäµÎãàÎã§. ÏßÄÏó≠ÌòÑÏïàÏÇ¨ÏóÖÏúºÎ°ú Î∞òÍ∏∞Î¨∏ Ïú†ÏóîÏÇ¨Î¨¥Ï¥ùÏû•Îãò\n",
            "   3  Ï†ú208Ìöå ÏûÑÏãúÌöå Ìú¥ÌöåÏùò Í±¥ÏùÄ Í∏àÎ≤à ÌöåÍ∏∞ Ï§ë Ï¶ùÌèâ·ÜûÏßÑÏ≤ú, Í¥¥ÏÇ∞·ÜûÏùåÏÑ± Íµ≠ÌöåÏùòÏõê Î≥¥Í∂êÏÑ†Í±∞Î°ú Ìú¥ÌöåÍ∞Ä ÏÑ†Ìè¨Îê®. Ï†ú4Ï∞® Î≥∏ÌöåÏùòÎäî 29Ïùº Ïò§ÌõÑ 2ÏãúÎ∂ÄÌÑ∞ Í≥ÑÏÜçÌï¥ÏÑú 2010ÎÖÑÎèÑ Íµ∞Ï†ï\n",
            "   4  Ï†ú40Ìöå Ï≤≠Ï£ºÏãúÏùòÌöå ÏûÑÏãúÌöå ÌöåÍ∏∞Îäî 2Ïõî 18ÏùºÎ∂ÄÌÑ∞ 2Ïõî 22ÏùºÍπåÏßÄ 5ÏùºÍ∞ÑÏúºÎ°ú Í∞ÄÍ≤∞Îê®. Ïù¥Ïû¨Í∏∏ ÏùòÏõê Ïô∏ Ïó¨Îçü Î∂ÑÏúºÎ°úÎ∂ÄÌÑ∞ Î∞úÏùòÎêú Ï≤≠Ï£ºÏãúÏû• Î∞è Í¥ÄÍ≥ÑÍ≥µÎ¨¥Ïõê Ï∂úÏÑùÏöîÍµ¨Ïùò Í±¥ÏùÄ ÏãúÏ†ïÏßàÎ¨∏ÏùÑ ÌïòÏã§ ÏùòÏõê\n",
            "   5  2016ÎÖÑÎèÑ Ïû¨ÎÇúÎåÄÏùë ÏïàÏ†ÑÌïúÍµ≠ÌõàÎ†®. Ïû¨ÎÇúÏïàÏ†ÑÎåÄÏ±ÖÎ≥∏Î∂Ä Ïö¥ÏòÅ ÌõàÎ†® Î∞è ÌòÑÏû•ÌõàÎ†®ÏùÑ 5ÏõîÍ≤Ω Ïã§ÏãúÌï† Í≥ÑÌöçÏù¥Î©∞, Ïû¨ÎÇúÍ¥ÄÎ¶¨Ï±ÖÏûÑÍ∏∞Í¥Ä Í∞Ñ Í≥µÏ°∞ Î∞è ÌòëÎ†•Ï≤¥Ï†ú Íµ¨Ï∂ïÏóê ÌûòÏì∞ÎèÑÎ°ù Ìï† Í≤É. Ïû¨ÎÇú ÎåÄÏùë ÏïàÏ†ÑÏ¥ùÍ¥ÑÍ≥º ÏÜåÍ¥Ä Ï£ºÏöî ÏóÖÎ¨¥\n",
            "   6  Ï†ú214Ìöå ÏôÑÏ£ºÍµ∞ÏùòÌöå ÏûÑÏãúÌöå Ï†ú1Ï∞® Î≥∏ÌöåÏùò Í∞úÏùò ÏÑ†Ìè¨. ÏùòÏÇ¨ÌåÄÏû•ÏúºÎ°úÎ∂ÄÌÑ∞ ÏùòÌöåÍ¥ÄÎ†®ÏÇ¨Ìï≠Ïóê ÎåÄÌïú Î≥¥Í≥†Í∞Ä ÏûàÏùÑ Í≤É. ÏùòÏÇ¨ÌåÄÏû• ÏÑúÎÇ®Ïö© ÏùòÏõê, Î∂ÄÏùòÏû•, ÏÉÅÏûÑÏúÑÏõêÏû• ÏÑ†Í±∞Ïóê ÎåÄÌïú ÏùòÍ≤¨Ï°∞Ïú®Ïù¥ ÏõêÎßåÌïòÏßÄ ÏïäÏïòÎçò Í¥ÄÍ≥Ñ\n",
            "   7  ÏùåÏÑ±Íµ∞Í∞ÑÏù¥ÏÉÅÏàòÎèÑÍ¥ÄÎ¶¨Ï°∞Î°Ä ÏùºÎ∂ÄÎÇ¥Ïö©ÏùÑ Î≤ïÎ†πÍ≥º ÏùºÏπòÌïòÎèÑÎ°ù Ï†ïÎ¶¨ÌïòÎäî ÌïúÌé∏ Í∞ÑÏù¥ÏÉÅ ÏàòÎèÑ Î∞è ÏÜåÍ∑úÎ™®Í∏âÏàòÏãúÏÑ§Ïóê ÎåÄÌïú ÏàòÏßàÍ≤ÄÏÇ¨ Î∞è ÏãúÏÑ§Ï†êÍ≤ÄÏùÑ Î∂ÑÍ∏∞ 1Ìöå Ïù¥ÏÉÅ Ïã§ÏãúÌïòÎèÑÎ°ù ÏùòÎ¨¥ÌôîÌï®. Ìï¥Îãπ ÏïàÍ±¥ÏùÄ Í∞Ä\n",
            "   8  Ï†ú226Ìöå ÏôÑÏ£ºÍµ∞ÏùòÌöå Ï†ú2Ï∞® Ï†ïÎ°ÄÌöåÏùò Ï†ú2Ï∞® Î≥∏ÌöåÏùò Í∞úÏùò ÏÑ†Ìè¨. ÏùòÏÇ¨ÌåÄÏû• Ïù¥ÏùÄÎØ∏. Ï†ú1Ï∞® Î≥∏ÌöåÏùò Ïù¥ÌõÑ ÏùòÏïà Ï†ëÏàòÏÇ¨Ìï≠. ÏßÄÎÇú 11Ïõî 21Ïùº Ïú§ÏàòÎ¥â ÏùòÏõê Î∞úÏùòÎ°ú Î∞úÏùòÎêòÏñ¥ Î≥∏ÌöåÏùòÏóê ÏßÅÏ†ë Î∂ÄÏùòÌïòÏòÄÏùå.\n",
            "   9  Í∑†ÌòïÍ∞úÎ∞úÍ≥º ÏÜåÍ¥Ä Ï£ºÏöî ÌòÑÏïàÏÇ¨ÏóÖ Î≥¥Í≥†Î•º ÎßàÏπòÍ≤†ÏäµÎãàÎã§. ÏÑúÌö®ÏÑù ÏùòÏõêÎãò ÏßàÏùòÌïòÏó¨ Ï£ºÏãúÍ∏∞ Î∞îÎûçÎãàÎã§. Ìï¥Îãπ ÏïàÍ±¥ÏùÄ ÏùåÏÑ±Ïùç ÎÜçÏ¥å Ï§ëÏã¨ÏßÄ ÌôúÏÑ±ÌôîÏÇ¨ÏóÖÏù¥ ÎÇ¥ÎÖÑÎèÑ 12ÏõîÍπåÏßÄ Í≥ÑÌöçÏù¥ Ïû°ÌòÄ ÏûàÎäîÎç∞ ÌòÑÏû¨ Ï∂îÏßÑÎêòÍ≥† ÏûàÎäî ÏÇ¨Ìï≠Ïù¥ Í≥ÑÌöçÎåÄÎ°ú ÏõêÎßå\n",
            "  10  2014ÎÖÑÎèÑ Ï†ú2Ï∞® ÏàòÏãúÎ∂Ñ Í≥µÏú†Ïû¨ÏÇ∞ Í¥ÄÎ¶¨Í≥ÑÌöçÏïàÍ≥º ÏùåÏÑ±Íµ∞ Ïû¨ÏÇ∞ÏÑ∏ ÎèÑÏãúÏßÄÏó≠Î∂Ñ Ï†ÅÏö©ÎåÄÏÉÅÏßÄÏó≠ Î≥ÄÍ≤ΩÍ≥†ÏãúÏïàÏùÄ Í≥µÏú†Ïû¨ÏÇ∞Ïùò Ï∑®ÎìùÏóê ÏïûÏÑúÏÑú ÏùåÏÑ±Íµ∞ÏùòÌöåÏùò ÏùòÍ≤∞ÏùÑ Î∞õÍ≥†Ïûê Ï†úÏïàÌï®. Ìï¥Îãπ ÏïàÍ±¥ÏùÄ Í∞ÄÍ≤∞Îê®.\n",
            "  11  Ï†ú193Ìöå ÏùåÏÑ±Íµ∞ÏùòÌöå ÏûÑÏãúÌöå ÌöåÍ∏∞Îäî 7Ïõî 7Ïùº Ïò§Îäò ÌïòÎ£®ÎèôÏïà Í∞ÄÍ≤∞Îê®. („ÄåÏóÜÏäµÎãàÎã§„ÄçÌïòÎäî ÏùòÏõê ÏûàÏùå. Ìï¥Îãπ ÏùòÏõêÏùÄ ÏóÜÏùå) ÏùòÏÇ¨ÏùºÏ†ïÏùÑ ÏÑ†Ìè¨Ìï®. ÏùòÏÇ¨Îäî Ïù¥ÏùòÍ∞Ä ÏóÜÏúºÎØÄÎ°ú Í∞Ä\n",
            "  12  Ï£ºÏöîÏÇ¨ÏóÖ ÌòÑÏßÄÌôïÏù∏ ÌäπÎ≥ÑÏúÑÏõêÌöå Íµ¨ÏÑ± Í≤∞ÏùòÏïàÏùÄ ÏùåÏÑ±Íµ∞Ïùò ÌòÑÏïàÏÇ¨ÏóÖÍ≥º 2010ÎÖÑÎèÑ ÌñâÏ†ïÏÇ¨Î¨¥Í∞êÏÇ¨ Ïãú ÏßÄÏ†ÅÎêú ÏÇ¨ÏóÖ, Íµ¨Ï†úÏó≠ Îß§Î™∞ÏßÄÏóê ÎåÄÌïòÏó¨ ÌòÑÏßÄÌôïÏù∏ÏùÑ ÌïòÍ≥†, ÏÇ¨ÏóÖÏùò Ï∂îÏßÑÏÇ¨Ìï≠ÏùÑ Ï†êÍ≤ÄÌïòÏó¨ Î∂ÄÏã§Í≥µÏÇ¨Î•º ÏÇ¨Ï†ÑÏóê ÏòàÎ∞©ÌïòÍ≥† ÏÇ¨ÏóÖÏòàÏÇ∞Ïù¥\n",
            "  13  ÏùåÏÑ±Íµ∞ Ï†ÄÏÜåÎìùÏ£ºÎØºÏûêÎÖÄ Ïû•ÌïôÍ∏à ÏßÄÍ∏â Ï°∞Î°Ä Ï†ÑÎ∂ÄÍ∞úÏ†ïÏ°∞Î°ÄÏïàÏùÄ Ï†ÄÏÜåÎìùÏ∏µ Î≤îÏúÑÎ•º ÌôïÎåÄÌïòÏó¨ Ï†ÄÏÜåÎìùÏ∏µ ÏûêÎÖÄ Ï§ë Î™®Î≤îÏ†ÅÏù∏ ÌïôÏÉù, Ïòà·ÜûÏ≤¥Îä• ÌäπÍ∏∞ÏÉùÏù¥ Ìè¨Ìï®ÎêòÎèÑÎ°ù ÏßÄÍ∏âÎåÄÏÉÅÏûêÎ•º ÌôïÎåÄ Ï∂îÍ∞ÄÌïòÍ≥†, Ïïà Ï†ú8Ï°∞ÏóêÎäî Ïû•ÌïôÏÉù\n",
            "  14  Ï†ú66Ìöå ÏôÑÏ£ºÍµ∞ÏùòÌöå ÏûÑÏãúÌöå Ï†ú1Ï∞® Î≥∏ÌöåÏùò Í∞úÏùò ÏÑ†Ìè¨. Ìï¥Îãπ ÏïàÍ±¥ÏùÄ Ï≤òÎ¶¨ÌïòÍ∏∞ ÏúÑÌïú ÏßëÌöå ÏöîÍµ¨Í∞Ä ÏûàÏñ¥ Í∞ÄÍ≤∞Îê®. '99ÎÖÑ 1Ïõî 27Ïùº Ïù¥ÏßÑÏ≤† ÏùòÏõê Ïô∏ 6Ïù∏ÏúºÎ°úÎ∂ÄÌÑ∞ ÏôÑÏ£ºÏûêÍµ∞Ï†úÏ¶ùÎ™ÖÎì± ÏàòÏàòÎ£å\n",
            "  15  2018ÎÖÑÎèÑ Ï£ºÏöîÏóÖÎ¨¥ Î≥¥Í≥†Ïùò Í±¥Ïù¥ ÏÉÅÏ†ïÎê®. Ïò§ÎäòÏùÄ Í±¥ÏÑ§ÍµêÌÜµÍ≥º, ÎèÑÏãúÍ≥º, ÏÇ∞ÏóÖÍ∞úÎ∞úÍ≥º, Í±¥Ï∂ïÌóàÍ∞ÄÍ≥º ÏàúÏúºÎ°ú Î≥¥Í≥†Î•º Î∞õÍ≤†ÏäµÎãàÎã§. Í∞ÄÏ∞Ω ÏïàÍ±¥ÏùÄ ÏÉÅÏ†ï. Í∞ÄÍ≤∞. Í±¥Ï∂ïÌóàÍ∞ÄÏùò Í±¥ÏùÑ ÏÉÅÏ†ïÌï©ÎãàÎã§. Í∞ÄÍ±¥ ÏïàÍ±¥ ÏÉÅÏ†ï\n",
            "\n",
            "Target summaries:\n",
            "\n",
            "  Id  Target summary\n",
            "----  -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "   0  ÏòàÏÇ∞Í≤∞ÏÇ∞ ÌäπÎ≥ÑÏúÑÏõêÌöåÎäî ÏµúÍ¥ÄÏãù ÏùòÏõê, ÎÇ®Í∂ÅÏú† ÏùòÏõê, ÍπÄÏö∞Ïãù ÏùòÏõê, Í≥†Ïû¨Ìòë ÏùòÏõê, ÍπÄÏÑ±Ï±Ñ ÏùòÏõê, ÏßÑÏùòÏû• ÏùòÏõê, Ïù¥Ï§ÄÍµ¨ ÏùòÏõê, ÍπÄÏ≤úÎ¥â ÏùòÏõêÏúºÎ°ú Íµ¨ÏÑ±Ìï®. ÌäπÎ≥ÑÏúÑÏõêÌöåÎäî Ï†ú2Ï∞® Ï†ïÎ°ÄÌöå Í∏∞Í∞Ñ Ï§ë ÏùòÏÇ¨ÏùºÏ†ïÏóê Îî∞ÎùºÏÑú 2002ÎÖÑÎèÑ ÏòàÏÇ∞Í≥º 2001ÎÖÑÎèÑ Ï†ú3Ìöå Ï∂îÍ∞ÄÍ≤ΩÏ†úÏòàÏÇ∞ÏùÑ Ïã¨ÏùòÌïòÍ≥†Ïûê Íµ¨ÏÑ±Ìï®. Ìï¥Îãπ ÏïàÍ±¥ÏùÄ Í∞ÄÍ≤∞Îê®.\n",
            "   1  ÏùåÏÑ±Íµ∞ ÏßÄÎ∞©ÏÑ∏ÏûÖÏßïÏàòÌè¨ÏÉÅÍ∏à ÏßÄÍ∏â Ï°∞Î°Ä ÏùºÎ∂ÄÍ∞úÏ†ïÏ°∞Î°ÄÏïàÏùÄ 2009ÎÖÑ 11Ïõî 1ÏùºÎ∂ÄÌÑ∞ Ï†ÑÍµ≠ ÏûêÏπòÎã®Ï≤¥ Í∞Ñ ÏßïÏàòÏ¥âÌÉÅÏ†úÎèÑ Ïö¥Ïö©Ïóê Îî∞Îùº ÏàòÌÉÅÍ∏∞Í¥ÄÏù¥ ÏßïÏàòÏ¥âÌÉÅÏúºÎ°ú ÏßïÏàò Ïãú ÍµêÎ∂ÄÎ∞õÏùÄ Í∏àÏï°Ïùò 10%Î•º Ïú†Í≥µÍ≥µÎ¨¥ÏõêÏóêÍ≤å ÏßÄÍ∏âÌïòÏó¨ ÏûêÎèôÏ∞®ÏÑ∏ ÏßïÏàòÏ¥âÌÉÅÏ†úÎ•º ÌôúÏÑ±ÌôîÌïòÍ≥†, Í≤∞ÏÜêÏ≤òÎ∂Ñ ÎØ∏ÏàòÏï°Ïùò 10%Î•º Ìè¨ÏÉÅÍ∏àÏúºÎ°ú ÏßÄÍ∏âÌïòÏó¨ Í≤∞ÏÜêÏÇ¨ÌõÑÍ¥ÄÎ¶¨Î•º ÏúÑÌïú ÏÑ∏Î¨¥Í≥µÎ¨¥ÏõêÏùò ÎÖ∏Î†• Í∞ïÌôîÎ°ú ÏÑ∏ÏàòÌôïÏ∂©ÏùÑ ÌïòÎ©∞, Ï°∞Î°Ä Ïö¥ÏòÅ ÏÉÅ ÎÇòÌÉÄÎÇú ÏùºÎ∂Ä Ï°∞Î¨∏ Î∞è Ïö©Ïñ¥Ïùò ÎØ∏ÎπÑÏ†êÏùÑ Ï†ïÎπÑÌïòÍ∏∞ ÏúÑÌï¥ Ï†úÏïàÎê®. Ìï¥Îãπ ÏïàÍ±¥ÏùÄ Í∞ÄÍ≤∞Îê®.\n",
            "   2  Í∂åÏó≠Î≥ÑÎ°ú ÏûàÎäî Ï§ëÍ≥†Îì±ÌïôÍµêÎèÑ Î™ÖÎ¨∏ÏùÑ ÎßåÎì§Í∏∞ ÏúÑÌï¥ÏÑú Íµ∞ÏóêÏÑúÎèÑ ÏßÄÏó≠Í≥º Í∑†ÌòïÏùÑ ÎßûÏ∂ú Í≤É.\n",
            "   3  Ï†ú208Ìöå ÏûÑÏãúÌöå Ìú¥ÌöåÏùò Í±¥ÏùÄ ÌöåÍ∏∞ Ï§ë Ï¶ùÌèâ, ÏßÑÏ≤ú, Í¥¥ÏÇ∞, ÏùåÏÑ± Íµ≠ÌöåÏùòÏõê Î≥¥Í∂êÏÑ†Í±∞Î°ú Ìú¥ÌöåÌï®.\n",
            "   4  Ï†ú40Ìöå Ï≤≠Ï£ºÏãúÏùòÌöå(ÏûÑÏãúÌöå)Ïùò ÌöåÍ∏∞Îäî 2Ïõî 18ÏùºÎ∂ÄÌÑ∞ 2Ïõî 22ÏùºÍπåÏßÄ 5ÏùºÍ∞ÑÏúºÎ°ú Í∞ÄÍ≤∞Îê®.\n",
            "   5  ÏïàÏ†ÑÏ¥ùÍ¥ÑÍ≥º ÏÜåÍ¥Ä Ï£ºÏöîÏóÖÎ¨¥ Î≥¥Í≥†.\n",
            "   6  Ï†ú214Ìöå ÏôÑÏ£ºÍµ∞ÏùòÌöå ÏûÑÏãúÌöå Ï†ú1Ï∞® Î≥∏ÌöåÏùò Í∞úÏùò ÏÑ†Ìè¨.\n",
            "   7  ÏùåÏÑ±Íµ∞Í∞ÑÏù¥ÏÉÅÏàòÎèÑÍ¥ÄÎ¶¨Ï°∞Î°ÄÍ∞úÏ†ïÏ°∞Î°ÄÏïàÏùÄ ÏàòÎèÑÎ≤ïÏùò Í∞úÏ†ïÏúºÎ°ú ÏùºÏ†ïÍ∑úÎ™® ÎØ∏ÎßåÏù∏ ÏãúÏÑ§ÏùÑ ÏÜåÍ∑úÎ™® Í∏âÏàòÏãúÏÑ§Î°ú Î∂ÑÎ•òÌï®Ïóê Îî∞Îùº Í∏∞Ï°¥Ïùò ÏùåÏÑ±Íµ∞Í∞ÑÏù¥ÏÉÅÏàòÎèÑÍ¥ÄÎ¶¨Ï°∞Î°ÄÎ•º Í∞úÏ†ï Î≤ïÎ†πÏùò ÎÇ¥Ïö©Ïóê Î∂ÄÌï©ÎêòÍ≤å Í∞úÏ†ïÌïòÏó¨ Í∞ÑÏù¥ÏÉÅÏàòÎèÑ Î∞è ÏÜåÍ∑úÎ™®Í∏âÏàòÏãúÏÑ§ÏùÑ Î≥¥Îã§ Ìö®Ïú®Ï†ÅÏúºÎ°ú Í¥ÄÎ¶¨ÌïòÍ∏∞ ÏúÑÌï¥ Ï†úÏïàÎê®. Ìï¥Îãπ ÏïàÍ±¥ÏùÄ Í∞ÄÍ≤∞Îê®.\n",
            "   8  Ï†ú226Ìöå ÏôÑÏ£ºÍµ∞ÏùòÌöå Ï†ú2Ï∞® Ï†ïÎ°ÄÌöå Ï†ú2Ï∞® Î≥∏ÌöåÏùò Í∞úÏùò ÏÑ†Ìè¨.\n",
            "   9  Í∑†ÌòïÍ∞úÎ∞úÍ≥º ÏÜåÍ¥Ä Ï£ºÏöî ÌòÑÏïàÏÇ¨ÏóÖ Î≥¥Í≥†.\n",
            "  10  2014ÎÖÑÎèÑ Ï†ú2Ï∞® ÏàòÏãúÎ∂Ñ Í≥µÏú†Ïû¨ÏÇ∞ Í¥ÄÎ¶¨Í≥ÑÌöçÏïàÏùÄ ÏùåÏÑ±Ïùç Ï≤≠ÏÇ¨Î•º Ïã†Ï∂ïÌïòÍ∏∞ ÏúÑÌï¥ Í≥µÏú†Ïû¨ÏÇ∞ Ï∑®Îìù Í≥ÑÌöçÏùÑ ÏùºÎ∂Ä Î≥ÄÍ≤Ω Ï∂îÏßÑÌïòÍ≥†Ïûê ÌïòÎäî Í≤ÉÏúºÎ°ú Ìï¥Îãπ ÏïàÍ±¥ÏùÄ Í∞ÄÍ≤∞Îê®. ÏùåÏÑ±Íµ∞ Ïû¨ÏÇ∞ÏÑ∏ ÎèÑÏãúÏßÄÏó≠Î∂Ñ Ï†ÅÏö©ÎåÄÏÉÅÏßÄÏó≠ Î≥ÄÍ≤ΩÍ≥†ÏãúÏïàÏùÄ ÏùåÏÑ±Íµ∞ ÎèÑÏãúÏßÄÏó≠ Î≥ÄÍ≤ΩÏóê Îî∞Îùº Ïû¨ÏÇ∞ÏÑ∏ ÎèÑÏãúÏßÄÏó≠Î∂Ñ Ï†ÅÏö©ÎåÄÏÉÅÏßÄÏó≠ÏùÑ Î≥ÄÍ≤ΩÌïòÏó¨ Í≥†ÏãúÌïòÍ≥†Ïûê Ï†úÏïàÌï®.\n",
            "  11  Ï†ú193Ìöå ÏùåÏÑ±Íµ∞ÏùòÌöå ÏûÑÏãúÌöåÏùò ÌöåÍ∏∞Îäî 7Ïõî 7Ïùº ÌïòÎ£®Î°ú Í∞ÄÍ≤∞Îê®.\n",
            "  12  ÏùåÏÑ±Íµ∞ Ï£ºÏöîÏÇ¨ÏóÖ ÌòÑÏßÄÌôïÏù∏ ÌäπÎ≥ÑÏúÑÏõêÌöå Íµ¨ÏÑ±ÏïàÏùÄ ÏùåÏÑ±Íµ∞Ïùò ÌòÑÏïàÏÇ¨ÏóÖÍ≥º 2010ÎÖÑÎèÑ ÌñâÏ†ïÏÇ¨Î¨¥Í∞êÏÇ¨ Ïãú ÏßÄÏ†ÅÎêú ÏÇ¨ÏóÖ, Íµ¨Ï†úÏó≠ Îß§Î™∞ÏßÄÏóê ÎåÄÌïú ÌòÑÏßÄÌôïÏù∏, ÏÇ¨ÏóÖÏùò Ï∂îÏßÑÏÇ¨Ìï≠ÏùÑ Ï†êÍ≤ÄÌïòÏó¨ Î∂ÄÏã§Í≥µÏÇ¨Î•º ÏÇ¨Ï†ÑÏóê ÏòàÎ∞©ÌïòÍ≥† ÏÇ¨ÏóÖÏòàÏÇ∞Ïù¥ ÌïÑÏöîÌïú Í≥≥Ïóê Ï†ÅÏ†àÌûà Ïì∞Ïùº Ïàò ÏûàÎèÑÎ°ù Ï£ºÏöîÏÇ¨ÏóÖ ÌòÑÏßÄÌôïÏù∏ ÌäπÎ≥ÑÏúÑÏõêÌöåÎ•º Íµ¨ÏÑ±ÌïòÍ≥†Ïûê Ìï®. Ï£ºÏöîÏÇ¨ÏóÖ ÌòÑÏßÄÌôïÏù∏ ÌäπÎ≥ÑÏúÑÏõêÌöå ÏúÑÏõêÏùÄ ÏÜêÏàòÏ¢Ö ÏùòÏõê, Ïù¥ÌïúÏ≤† ÏùòÏõê, ÎÇ®Í∂ÅÏú† ÏùòÏõê, Ï°∞Ï≤úÌù¨ ÏùòÏõê, ÏÜêÎã¨ÏÑ≠ ÏùòÏõê, Ïù¥ÎåÄÏõÖ ÏùòÏõê, ÍπÄÏàúÏò• ÏùòÏõêÏúºÎ°ú Íµ¨ÏÑ±ÌïòÍ≥†Ïûê Ìï®. Ìï¥Îãπ Í≤∞ÏùòÏïàÏùÄ Í∞ÄÍ≤∞ÎêòÏóàÏùå.\n",
            "  13  ÏùåÏÑ±Íµ∞ Ï†ÄÏÜåÎìùÏ£ºÎØºÏûêÎÖÄ Ïû•ÌïôÍ∏à ÏßÄÍ∏â Ï°∞Î°Ä Ï†ÑÎ∂ÄÍ∞úÏ†ïÏ°∞Î°ÄÏïàÏùÄ Ï†ÄÏÜåÎìùÏ∏µ Î≤îÏúÑ ÏôÑÌôî, Ïû•ÌïôÍ∏à ÏßÄÍ∏âÎåÄÏÉÅÏûê ÌôïÎåÄ Î∞è ÏÑ±Ï†ÅÏû•ÌïôÍ∏à Ï†úÏô∏ Îì± Ïû•ÌïôÍ∏à ÏßÄÍ∏â Í∏∞Ï§ÄÏùÑ Ï°∞Ï†ïÌïòÍ≥† ÏïåÍ∏∞ Ïâ¨Ïö¥ Î≤ïÎ†π Ï†ïÎπÑ Í∏∞Ï§ÄÏóê Îî∞ÎùºÏÑú Î∂àÌï©Î¶¨Ìïú Ï°∞Î¨∏ÏùÑ Ï†ïÎπÑÌïòÍ∏∞ ÏúÑÌïòÏó¨ Î≥∏ Ï°∞Î°ÄÎ•º Ï†ÑÎ∂ÄÍ∞úÏ†ï ÌïòÎ†§Í≥† Î∞úÏùòÌï®. Ìï¥Îãπ ÏïàÍ±¥ÏùÄ Í∞ÄÍ≤∞Îê®. ÏùåÏÑ±Íµ∞ ÏßÄÏó≠ÏïÑÎèôÏÑºÌÑ∞ Ïö¥ÏòÅ Î∞è ÏßÄÏõêÏóê Í¥ÄÌïú Ï°∞Î°ÄÏïàÏùÄ Î∞©Í≥º ÌõÑ ÎèåÎ¥ÑÏù¥ ÌïÑÏöîÌïú ÏßÄÏó≠ÏÇ¨Ìöå ÏïÑÎèôÏùò Í±¥Ï†ÑÌïú Ïù∏Í≤©Î∞úÎã¨Í≥º Ï†ïÏÑúÌï®ÏñëÏùÑ ÌÜµÌïòÏó¨ Í±¥Í∞ïÍ≥º Î≥µÏßÄÏ¶ùÏßÑÏùÑ ÎèÑÎ™®ÌïòÍ∏∞ ÏúÑÌï¥ Î∞úÏùòÌï®.\n",
            "  14  Ï†ú66Ìöå ÏôÑÏ£ºÍµ∞ÏùòÌöå ÏûÑÏãúÌöå Ï†ú1Ï∞® Î≥∏ÌöåÏùò Í∞úÏùò ÏÑ†Ìè¨.\n",
            "  15  2018ÎÖÑÎèÑ Ï£ºÏöîÏóÖÎ¨¥ Î≥¥Í≥†Ïùò Í±¥ÏùÄ Í±¥ÏÑ§ÍµêÌÜµÍ≥º, ÎèÑÏãúÍ≥º, ÏÇ∞ÏóÖÍ∞úÎ∞úÍ≥º, Í±¥Ï∂ïÌóàÍ∞ÄÍ≥º ÏàúÏúºÎ°ú Î≥¥Í≥† ÏßÑÌñâÌï®.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EaHUwSYunHIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Îü∞ÌÉÄÏûÑÏùÑ Ï¥àÍ∏∞Ìôî Ìïú Í≤ΩÏö∞\n",
        "- ÌïôÏäµÎêú Î™®Îç∏Ïù¥ `model` Î≥ÄÏàòÏóê Ï†ÄÏû•ÎêòÏñ¥ ÏûàÏßÄ ÏïäÍ∏∞ ÎïåÎ¨∏Ïóê Î™®Îç∏, ÌÜ†ÌÅ¨ÎÇòÏù¥Ï†ÄÎ•º Ï†ïÏùòÌï¥Ïïº Ìï©ÎãàÎã§.\n",
        "- ÏÉÅÎã® ÏΩîÎìúÏóêÏÑú Training Ïù¥Ï†ÑÍπåÏßÄÏùò ÏΩîÎìúÎ•º Ïã§ÌñâÌïòÏÖîÏïº Ìï©ÎãàÎã§.\n",
        "- `2.Training` Î∞îÎ°ú ÏúÑ ÏÖÄÏóêÏÑú \"Îü∞ÌÉÄÏûÑ -> Ïù¥Ï†Ñ ÏÖÄ Ïã§Ìñâ\"ÏùÑ ÌïòÏãúÎ©¥ Í∞ÑÌé∏Ìï©ÎãàÎã§.\n",
        "- Î°úÍ∑∏ Ìè¥Îçî ÏÑ§Ï†ïÏùÄ trainingÏùÑ ÌïòÏßÄ ÏïäÏúºÏãúÍ∏∞ ÎïåÎ¨∏Ïóê Ïã§ÌñâÌïòÏßÄ ÏïäÏúºÏÖîÎèÑ Îê©ÎãàÎã§."
      ],
      "metadata": {
        "id": "vrHesLZmnjFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_summary(test_samples, model):\n",
        "    inputs = tokenizer(\n",
        "        test_samples[\"context\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=encoder_max_length,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "    input_ids = inputs.input_ids.to(model.device)\n",
        "    attention_mask = inputs.attention_mask.to(model.device)\n",
        "    outputs = model.generate(input_ids, attention_mask=attention_mask, num_beams = 8, min_length = 10, max_length = 50,)\n",
        "    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "    return outputs, output_str"
      ],
      "metadata": {
        "id": "eIRQHYeDpwAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = 'results/kobart_base/2_20220928-0052/checkpoint/checkpoint-150' # pytorch_model.bin Îì±Ïù¥ Ìè¨Ìï®Îêú checkpoint pathÎ•º Î™ÖÏãúÌï¥Ï£ºÏÑ∏Ïöî (ÏòàÏãú, results/kobart_base/2_20220928-0052/checkpoint/checkpoint-150 )"
      ],
      "metadata": {
        "id": "daB9Ves3pKJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download model and tokenizer\n",
        "if model_pretrained == 'kykim/bertshared-kor-base':\n",
        "    from transformers import BertTokenizerFast, EncoderDecoderModel\n",
        "    tokenizer = BertTokenizerFast.from_pretrained(\"kykim/bertshared-kor-base\", model_max_length=512)\n",
        "    model = EncoderDecoderModel.from_pretrained(checkpoint_path) # checkpoint pathÎ•º Î™ÖÏãúÌï©ÎãàÎã§.\n",
        "    \n",
        "    model.config.min_length = None\n",
        "    model.config.decoder_start_token_id = tokenizer.cls_token_id\n",
        "    model.config.pad_token_id = tokenizer.pad_token_id\n",
        "    model.config.vocab_size = model.config.decoder.vocab_size\n",
        "    \n",
        "\n",
        "elif model_pretrained == 'hyunwoongko/asian-bart-ecjk':\n",
        "    # ÎùºÏù¥Î∏åÎü¨Î¶¨ ÏÑ§ÏπòÍ∞Ä ÌïÑÏöîÌï©ÎãàÎã§. (pip install asian-bart)\n",
        "    from asian_bart import AsianBartTokenizer, AsianBartForConditionalGeneration\n",
        "    tokenizer = AsianBartTokenizer.from_pretrained(\"hyunwoongko/asian-bart-ecjk\")\n",
        "    model = AsianBartForConditionalGeneration.from_pretrained(checkpoint_path)  # checkpoint pathÎ•º Î™ÖÏãúÌï©ÎãàÎã§.\n",
        "\n",
        "elif model_pretrained == 'paust/pko-t5-base':\n",
        "    from transformers import T5TokenizerFast, T5ForConditionalGeneration\n",
        "    tokenizer = T5TokenizerFast.from_pretrained('paust/pko-t5-base')\n",
        "    model = T5ForConditionalGeneration.from_pretrained(checkpoint_path)  # checkpoint pathÎ•º Î™ÖÏãúÌï©ÎãàÎã§.\n",
        "\n",
        "elif model_pretrained == 'facebook/mbart-large-50':\n",
        "    from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
        "    model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50\")\n",
        "    tokenizer = MBart50TokenizerFast.from_pretrained(checkpoint_path, src_lang=\"ko_KR\", tgt_lang=\"ko_KR\")  # checkpoint pathÎ•º Î™ÖÏãúÌï©ÎãàÎã§.\n",
        "\n",
        "elif model_pretrained in ['gogamza/kobart-base-v1', 'cosmoquester/bart-ko-mini', 'gogamza/kobart-summarization', 'gogamza/kobart-base-v2']:\n",
        "    tokenizer = PreTrainedTokenizerFast.from_pretrained(model_pretrained)\n",
        "    # Default pre-trained model is from https://github.com/seujung/KoBART-summarization \n",
        "    model = BartForConditionalGeneration.from_pretrained(checkpoint_path)  # checkpoint pathÎ•º Î™ÖÏãúÌï©ÎãàÎã§.\n",
        "\n",
        "else:\n",
        "    print(f\"Model {model_pretrained} is not supported\")\n",
        "    exit()\n",
        "\n",
        "print(model.config)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiRhuyR-nGrD",
        "outputId": "efad8482-1c10-445a-b6bb-e3286837fc18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BartConfig {\n",
            "  \"_name_or_path\": \"results/kobart_base/2_20220928-0052/checkpoint/checkpoint-150\",\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": false,\n",
            "  \"architectures\": [\n",
            "    \"BartForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
            "  \"bos_token_id\": 1,\n",
            "  \"classif_dropout\": 0.1,\n",
            "  \"classifier_dropout\": 0.1,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 3072,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 1,\n",
            "  \"do_blenderbot_90_layernorm\": false,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 3072,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 6,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"extra_pos_embeddings\": 2,\n",
            "  \"force_bos_token_to_be_generated\": false,\n",
            "  \"forced_eos_token_id\": 1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEGATIVE\",\n",
            "    \"1\": \"POSITIVE\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"kobart_version\": 2.0,\n",
            "  \"label2id\": {\n",
            "    \"NEGATIVE\": 0,\n",
            "    \"POSITIVE\": 1\n",
            "  },\n",
            "  \"max_position_embeddings\": 1026,\n",
            "  \"model_type\": \"bart\",\n",
            "  \"normalize_before\": false,\n",
            "  \"normalize_embedding\": true,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 3,\n",
            "  \"scale_embedding\": false,\n",
            "  \"static_position_embeddings\": false,\n",
            "  \"tokenizer_class\": \"PreTrainedTokenizerFast\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.22.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30000\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2BHimCFfrHQ"
      },
      "outputs": [],
      "source": [
        "# test Ìï† ÏÉòÌîå ÌÖçÏä§Ìä∏Î•º Í≥†Î¶ÖÎãàÎã§.\n",
        "test_samples = eval_data.select(range(16))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summaries_after_tuning = generate_summary(test_samples, model)[1]"
      ],
      "metadata": {
        "id": "oJ34OlokmxpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7IPtJLjCcmS",
        "outputId": "06e6cc9c-58af-4538-db09-8e10daafb981"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Id  Summary after\n",
            "----  -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "   0  ÏùòÏõêÎãò,Îãò, Ï£ºÏã† ÏÇ¨Ìï≠ÏúºÎ°ú, ÏòàÏÇ∞Í≤∞ÏÇ∞ÌäπÎ≥ÑÏúÑÏõêÌöå Íµ¨ÏÑ±ÏïàÏùÑ ÏÉÅÏ†ïÌï©ÎãàÎã§. ÏòàÏÇ∞Í≤∞ÏÇ∞ÌäπÎ≥ÑÏúÑÏõêÌöå Íµ¨ÏÑ±ÏùÄ Ïó¨Îçü Î∂ÑÏùò ÏùòÏõêÎãòÏúºÎ°ú Íµ¨ÏÑ±ÌïòÎèÑÎ°ù Íµ¨ÏÑ±ÌïòÎèÑÎ°ù ÌòëÏùòÎêú Î∞î, ÏÇ¨ÌöåÏûêÏù∏ Ï†úÍ∞Ä ÌäπÎ≥ÑÏúÑÏõêÌöå ÏúÑÏõêÏùÑ ÏßÄÎ™ÖÌïòÍ≤†ÏäµÎãàÎã§. ÏùòÏõê\n",
            "   1  ÌïòÏó¨ÌïòÏó¨ ÏÑ§Î™ÖÌïòÏó¨ Ï£ºÏãúÌïòÏó¨ Ï£ºÏãúÌïòÏó¨ Ï£ºÏãúÌïòÏó¨ Ï£ºÏãúÌïòÏó¨ Ï£ºÏãúÌïòÏó¨ Ï£ºÏãúÌïòÏó¨ Ï£ºÏãúÎãàÎã§.ÎãàÎã§. Ïû¨Î¨¥Í≥ºÏû•ÏûÖÎãàÎã§. Ïû¨Î¨¥Í≥ºÏû•ÏûÖÎãàÎã§. Î®ºÏ†Ä Î®ºÏ†Ä Î®ºÏ†Ä Î®ºÏ†Ä Î®ºÏ†Ä Î®ºÏ†Ä Î®ºÏ†Ä Î®ºÏ†Ä Î®ºÏ†Ä Î®ºÏ†Ä Î®ºÏ†Ä Î®ºÏ†Ä Î®ºÏ†Ä Î®ºÏ†Ä Î®ºÏ†Ä Î®ºÏ†Ä Î®ºÏ†Ä Î®ºÏ†Ä Î®ºÏ†Ä Î®ºÏ†Ä Î®ºÏ†Ä Î®ºÏ†Ä Î®ºÏ†Ä\n",
            "   2  Îã§ Îã§ÏãúÏ±Ö, ÌäπÏàòÏãúÏ±Ö, ÌäπÏàòÏãúÏ±Ö ÏàúÏúºÎ°ú Î≥¥Í≥†ÎìúÎ¶¨Í≤†ÏäµÎãàÎã§. Î®ºÏ†Ä 2008ÎÖÑ ÏÉÅÎ∞òÍ∏∞ Ï£ºÏöîÏóÖÎ¨¥ Ï∂îÏßÑÏã§Ï†ÅÏûÖÎãàÎã§. 3ÌéòÏù¥ÏßÄÍ∞Ä ÎêòÍ≤†ÏäµÎãàÎã§. Î®ºÏ†Ä 2008ÎÖÑ ÏÉÅÎ∞òÍ∏∞ Ï£ºÏöîÏóÖÎ¨¥ Ï∂îÏßÑÏã§Ï†ÅÏûÖÎãàÎã§. 3ÌéòÏù¥ÏßÄÍ∞Ä ÎêòÍ≤†ÏäµÎãàÎã§. Ï£ºÏöî Íµ∞Ï†ïÏ∂î\n",
            "   3  Ï†ú208Ìöå ÏûÑÏãúÌöå Ìú¥ÌöåÏùò Í±¥ÏùÄ Í∏àÎ≤à ÌöåÍ∏∞ Ï§ë Ï¶ùÌèâ·ÜûÏßÑÏ≤ú·ÜûÍ¥¥ÏÇ∞·ÜûÍ¥¥ÏÇ∞·ÜûÏùåÏÑ± Íµ≠ÌöåÏùòÏõê Î≥¥Í∂êÏÑ†Í±∞Î°ú Ìú¥ÌöåÌïòÏò§Îãà ÏñëÌï¥ÌïòÏó¨ Ï£ºÏãúÍ∏∞ Î∞îÎûçÎãàÎã§. Ïù¥ÏÉÅÏúºÎ°ú Ïò§ÎäòÏùò Í≥ÑÌöçÎêú\n",
            "   4  Ï†ú Ï†úÏù¥ Ï†ú40Ìöå Ï≤≠Ï£ºÏãúÏùòÌöå(ÏûÑÏãúÌöå) ÌöåÍ∏∞Í≤∞Ï†ïÏùò Í±¥ÏùÑ ÏÉÅÏ†ïÌï©ÎãàÎã§. Ïù¥Î≤à ÏûÑÏãúÌöå ÌöåÍ∏∞Îäî ÏùòÌöåÏö¥ÏòÅÏúÑÏõêÌöåÏôÄ ÌòëÏùòÌïú Î∞îÏôÄ Í∞ôÏù¥ 2Ïõî 18ÏùºÎ∂ÄÌÑ∞ 2Ïõî 22ÏùºÍπåÏßÄ 5ÏùºÍ∞ÑÏúºÎ°ú ÌïòÍ≥†Ïûê ÌïòÎäîÎç∞ ÏùòÏõê Ïó¨Îü¨Î∂Ñ\n",
            "   5  ÏßÄ Î∞è ÌòÑÏû• ÌòÑÏû• ÌõàÎ†® Î∞è ÌòÑÏû•ÌõàÎ†®ÏùÑ 5ÏõîÍ≤Ω Ïã§ÏãúÌï† ÌõàÎ†® Î∞è ÌòÑÏû•ÌõàÎ†®ÏùÑ 5ÏõîÍ≤Ω Ïã§ÏãúÌï† Í≥ÑÌöçÏù¥Î©∞, Ïã§ÏßàÏ†Å Ïû¨ÎÇúÎåÄÏùë Ïó≠ÎüâÍ∞ïÌôîÎ°ú ÏïàÏ†Ñ ÏùåÏÑ± Ïã§ÌòÑÍ≥º ÌòëÎ†•Ï≤¥Ï†ú Íµ¨Ï∂ïÏóê ÌòëÎ†•Ï≤¥Ï†ú Íµ¨Ï∂ïÏóê ÌûòÏì∞ÎèÑÎ°ù ÌïòÍ≤†ÏäµÎãàÎã§. Î®ºÏ†Ä 3ÌéòÏù¥ÏßÄ\n",
            "   6  Í¥ÄÍ≥ÑÎ°ú ÏßÄÏó∞ÎêêÏùåÏùÑ ÏñëÌï¥Î∞îÎûçÎãàÎã§. ÏßÄÎ∞©ÏûêÏπòÎ≤ï Ï†ú63Ï°∞Ï†ú1Ìï≠Ïóê Îî∞Îùº Ïû¨Ï†ÅÏùòÏõê 3Î∂ÑÏùò1 Ïù¥ÏÉÅÏùò ÏùòÏõêÏù¥ Ï∂úÏÑùÌïòÏÖ®Í∏∞ ÎïåÎ¨∏Ïóê ÏùòÏÇ¨Ï†ïÏ°±ÏàòÏóê Îã¨ÌïòÏòÄÏúºÎØÄÎ°ú 1Ï∞® Î≥∏ÌöåÏùò Í∞úÏùòÎ•º ÏãúÏûëÌïòÍ≤†ÏäµÎãàÎã§. ÏÑ±ÏõêÏù¥ ÎêòÏóà\n",
            "   7  Ï°∞Ï°∞Î°Ä Í∞úÏ†ïÏ°∞Î°ÄÏóê ÎåÄÌïòÏó¨ Î≥¥Í≥† ÏÑ§Î™ÖÌïòÏó¨ Ï£ºÏãúÍ∏∞ Î∞îÎûçÎãàÎã§. ÏßÄÏó≠Í∞úÎ∞úÍ≥ºÏû• Ïú§ÏòÅÌï¥ÏûÖÎãàÎã§. ÏùåÏÑ±Íµ∞Í∞ÑÏãúÏû•Ï°∞Î°ÄÍ∞úÏ†ïÏ°∞Î°ÄÏïàÏóê ÎåÄÌïòÏó¨ Î≥¥Í≥† ÎìúÎ¶¨Í≤†ÏäµÎãàÎã§. Ï†úÏïàÏÇ¨Î°ÄÏóê ÎåÄÌïòÏó¨ Î≥¥Í≥† ÎìúÎ¶¨Í≤†ÏäµÎãàÎã§. Ï†úÏïàÏÇ¨Î°ÄÏóê\n",
            "   8  ÏûÖÎãàÎã§. Î®ºÏ†Ä ÏùòÏÇ¨ÌåÄÏû•ÏúºÎ°úÎ∂ÄÌÑ∞ ÏùòÌöå Í¥ÄÎ†® ÏÇ¨Ìï≠Ïóê ÎåÄÌïú Î≥¥Í≥†Í∞Ä ÏûàÍ≤†ÏäµÎãàÎã§. ÏùòÏÇ¨ÌåÄÏû•ÏùÄ Î≥¥Í≥†ÌïòÏó¨ Ï£ºÏãúÍ∏∞ Î∞îÎûçÎãàÎã§. ÏùòÏÇ¨ÌåÄÏû• Ïù¥ÏùÄÎØ∏ÏûÖÎãàÎã§. Î≥¥Í≥†ÏÇ¨Ìï≠ÏùÑ ÎßêÏîÄÎìúÎ¶¨Í≤†ÏäµÎãàÎã§. Î®ºÏ†Ä, Ï†ú1Ï∞® Î≥∏ÌöåÏùò Ïù¥ÌõÑ ÏùòÏïà Ï†ëÏàòÏÇ¨Ìï≠ÏûÖÎãàÎã§. ÏßÄÎÇú 11Ïõî 21Ïùº\n",
            "   9  Ìï©ÎãàÎã§.Ìï©ÎãàÎã§.Ìï©ÎãàÎã§. Í≤É Í≤É Í≤É Í≤É Í≤É Í≤É Í≤É Í∞ôÏùÄÎç∞ Í∑∏Í≤É ÎïåÎ¨∏Ïóê ÏùåÏÑ±ÏùçÏ≤≠ÏÇ¨ Î¶¨Î™®Îç∏ÎßÅÏù¥ ÏßÄÏó∞ÎêòÍ≥† ÏûàÏäµÎãàÎã§. Í∑∏Í≤É Ïô∏ÏóêÎèÑ Ï∂îÏßÑÏúÑÏõêÌöåÌïòÍ≥† Í≥µÏÇ¨ÏóÖÏ≤¥ Í¥ÄÍ≥ÑÍ∞Ä ÏõêÎßåÌïòÏßÄ Î™ªÌïú Î∂ÄÎ∂ÑÏù¥ ÎçîÎü¨ ÏûàÎäî Í≤É Í∞ôÏäµÎãàÎã§. Í∑∏ÎûòÏÑú Í∑∏Îü∞ Î∂ÄÎ∂ÑÎèÑ Ï±ôÍ≤®ÏÑú ÏõêÎßå\n",
            "  10  ÏùòÏÇ¨ÏùºÏ†ï Ï†ú8Ìï≠, 2014ÎÖÑÎèÑ Ï†ú2Ï∞® ÏàòÏãúÎ∂Ñ Í≥µÏú†Ïû¨ÏÇ∞ Í¥ÄÎ¶¨ Í≥ÑÌöçÏïà, ÏùòÏÇ¨ÏùºÏ†ï Ï†ú9Ìï≠, ÏùåÏÑ±Íµ∞ Ïû¨ÏÇ∞ÏÑ∏ ÎèÑÏãúÏßÄÏó≠Î∂Ñ Ï†ÅÏö©ÎåÄÏÉÅÏßÄÏó≠ Î≥ÄÍ≤ΩÍ≥†ÏãúÏïàÏùÑ Í≥ÑÏÜçÌï¥ÏÑú ÏùºÍ¥Ñ ÏÉÅÏ†ïÌï©ÎãàÎã§. Ïû¨Î¨¥Í≥ºÏû•ÍªòÏÑúÎäî ÎÇòÏò§ÏÖîÏÑú\n",
            "  11  Ï†ú193Ìöå ÏùåÏÑ±Íµ∞ÏùòÌöå ÏûÑÏãúÌöå ÌöåÍ∏∞Í≤∞Ï†ïÏùò Í±¥ÏùÑ ÏÉÅÏ†ïÌï©ÎãàÎã§. Ï†ú193Ìöå ÏùåÏÑ±Íµ∞ÏùòÌöå ÏùåÏÑ±Íµ∞Ìöå ÏûÑÏãúÌöå ÌöåÍ∏∞Îäî Ïó¨Îü¨ ÏùòÏõêÎãòÎì§ÍªòÏÑú ÏÇ¨Ï†ÑÏóê ÏñëÌï¥ÌïòÏó¨ Ï£ºÏã†ÎåÄÎ°ú 7Ïõî 7Ïùº Ïò§Îäò ÌïòÎ£®ÎèôÏïà ÌïòÍ≥†Ïûê\n",
            "  12  Ìï®Íªò Ìï®Íªò Ìï®Íªò Ìï®Íªò Ìï®Íªò Ìï®Íªò Ìï®Íªò Ìï®Íªò Ìï®Íªò Ìï®Íªò Ìï®Íªò Ï£ºÏãúÍ∏∞ Î∞îÎûçÎãàÎã§. ÎåÄÌëú Î∞úÏùòÌïòÏã† ÏÜêÎã¨ÏÑ≠ ÏùòÏõêÎãòÍªòÏÑúÎäî ÎÇòÏò§ÏÖîÏÑú ÌäπÎ≥ÑÏúÑÏõêÌöå Íµ¨ÏÑ±ÏïàÏóê ÎåÄÌïòÏó¨ Ï†úÏïà ÏÑ§Î™ÖÏùÑ ÌïòÏó¨ Ï£ºÏãúÍ∏∞ Î∞îÎûçÎãàÎã§. ÏÜêÎã¨ÏÑ≠ ÏùòÏõêÏûÖÎãàÎã§.ÏûÖÎãàÎã§. ÏÜêÎã¨ÏÑ≠\n",
            "  13  Ï†ïÏ†ïÏ°∞Î°ÄÏïà, ÏùòÏÇ¨ÏùºÏ†ï Ï†ú6Ìï≠, ÏùåÏÑ±Íµ∞ ÏßÄÏó≠ÏïÑÎèôÏÑºÌÑ∞ Ïö¥ÏòÅ Î∞è ÏßÄÏõêÏóê Í¥ÄÌïú Ï°∞Î°ÄÏïàÏùÑ ÏùºÍ¥Ñ ÏÉÅÏ†ïÌï©ÎãàÎã§. Ï£ºÎØºÎ≥µÏßÄÏã§Ïû•ÍªòÏÑúÎäî ÎÇòÏò§ÏÖîÏÑú Îëê Í±¥Ïùò ÏïàÍ±¥Ïóê ÎåÄÌï¥ÏÑú ÏùºÍ¥Ñ Ï†úÏïàÏÑ§Î™ÖÌï¥ Ï£ºÏãúÍ∏∞ Î∞îÎûçÎãàÎã§. Ï£ºÎØºÎ≥µÏßÄÏã§Ïû•\n",
            "  14  Î≥¥Í≥† Î≥¥Í≥† Î≥¥Í≥†Í∞Ä ÏûàÍ≤†ÏäµÎãàÎã§. Î≥¥Í≥†ÏÇ¨Ìï≠ÏùÑ ÎßêÏîÄ ÎßêÏîÄ ÎßêÏîÄÎìúÎ¶¨Í≤†ÏäµÎãàÎã§. Î≥¥Í≥†ÏÇ¨Ìï≠ÏùÑ ÎßêÏîÄ ÎßêÏîÄÎìúÎ¶¨Í≤†ÏäµÎãàÎã§. Î≥¥Í≥†ÏÇ¨Ìï≠ÏùÑ ÎßêÏîÄÎìúÎ¶¨Í≤†ÏäµÎãàÎã§.  '99ÎÖÑ 1Ïõî 27Ïùº ÏôÑÏ£ºÍµ∞ÏàòÎ°úÎ∂ÄÌÑ∞ ÏôÑÏ£ºÍµ∞Ï†úÏ¶ùÎ™ÖÎì± ÏàòÏàòÎ£åÏßïÏàòÏ°∞Î°ÄÏ§ë\n",
            "  15  ÏùòÏÇ¨ÏùºÏ†ï Ï†ú1Ìï≠, 2018ÎÖÑÎèÑ Ï£ºÏöîÏóÖÎ¨¥ Î≥¥Í≥†Ïùò Í±¥ÏùÑ ÏÉÅÏ†ïÌï©ÎãàÎã§. Ïò§ÎäòÏùÄ Í±¥ÏÑ§ÍµêÌÜµÍ≥º, ÎèÑÏãúÍ≥º, ÏÇ∞ÏóÖÍ∞úÎ∞úÍ≥º, Í±¥Ï∂ïÍ∞úÎ∞úÍ≥º, Í±¥Ï∂ïÌóàÍ∞ÄÍ≥º ÏàúÏúºÎ°ú Î≥¥Í≥†Î•º Î∞õÍ≤†ÏäµÎãàÎã§. Í∑∏Îüº Î®ºÏ†Ä Í±¥ÏÑ§ÍµêÌÜµÍ≥º, ÎèÑÏãúÍ≥º, ÏÇ∞ÏóÖÍ∞úÎ∞úÍ≥º, Í±¥Ï∂ïÍ∞úÎ∞úÍ≥º,\n",
            "\n",
            "Target summaries:\n",
            "\n",
            "  Id  Target summary\n",
            "----  -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "   0  ÏòàÏÇ∞Í≤∞ÏÇ∞ ÌäπÎ≥ÑÏúÑÏõêÌöåÎäî ÏµúÍ¥ÄÏãù ÏùòÏõê, ÎÇ®Í∂ÅÏú† ÏùòÏõê, ÍπÄÏö∞Ïãù ÏùòÏõê, Í≥†Ïû¨Ìòë ÏùòÏõê, ÍπÄÏÑ±Ï±Ñ ÏùòÏõê, ÏßÑÏùòÏû• ÏùòÏõê, Ïù¥Ï§ÄÍµ¨ ÏùòÏõê, ÍπÄÏ≤úÎ¥â ÏùòÏõêÏúºÎ°ú Íµ¨ÏÑ±Ìï®. ÌäπÎ≥ÑÏúÑÏõêÌöåÎäî Ï†ú2Ï∞® Ï†ïÎ°ÄÌöå Í∏∞Í∞Ñ Ï§ë ÏùòÏÇ¨ÏùºÏ†ïÏóê Îî∞ÎùºÏÑú 2002ÎÖÑÎèÑ ÏòàÏÇ∞Í≥º 2001ÎÖÑÎèÑ Ï†ú3Ìöå Ï∂îÍ∞ÄÍ≤ΩÏ†úÏòàÏÇ∞ÏùÑ Ïã¨ÏùòÌïòÍ≥†Ïûê Íµ¨ÏÑ±Ìï®. Ìï¥Îãπ ÏïàÍ±¥ÏùÄ Í∞ÄÍ≤∞Îê®.\n",
            "   1  ÏùåÏÑ±Íµ∞ ÏßÄÎ∞©ÏÑ∏ÏûÖÏßïÏàòÌè¨ÏÉÅÍ∏à ÏßÄÍ∏â Ï°∞Î°Ä ÏùºÎ∂ÄÍ∞úÏ†ïÏ°∞Î°ÄÏïàÏùÄ 2009ÎÖÑ 11Ïõî 1ÏùºÎ∂ÄÌÑ∞ Ï†ÑÍµ≠ ÏûêÏπòÎã®Ï≤¥ Í∞Ñ ÏßïÏàòÏ¥âÌÉÅÏ†úÎèÑ Ïö¥Ïö©Ïóê Îî∞Îùº ÏàòÌÉÅÍ∏∞Í¥ÄÏù¥ ÏßïÏàòÏ¥âÌÉÅÏúºÎ°ú ÏßïÏàò Ïãú ÍµêÎ∂ÄÎ∞õÏùÄ Í∏àÏï°Ïùò 10%Î•º Ïú†Í≥µÍ≥µÎ¨¥ÏõêÏóêÍ≤å ÏßÄÍ∏âÌïòÏó¨ ÏûêÎèôÏ∞®ÏÑ∏ ÏßïÏàòÏ¥âÌÉÅÏ†úÎ•º ÌôúÏÑ±ÌôîÌïòÍ≥†, Í≤∞ÏÜêÏ≤òÎ∂Ñ ÎØ∏ÏàòÏï°Ïùò 10%Î•º Ìè¨ÏÉÅÍ∏àÏúºÎ°ú ÏßÄÍ∏âÌïòÏó¨ Í≤∞ÏÜêÏÇ¨ÌõÑÍ¥ÄÎ¶¨Î•º ÏúÑÌïú ÏÑ∏Î¨¥Í≥µÎ¨¥ÏõêÏùò ÎÖ∏Î†• Í∞ïÌôîÎ°ú ÏÑ∏ÏàòÌôïÏ∂©ÏùÑ ÌïòÎ©∞, Ï°∞Î°Ä Ïö¥ÏòÅ ÏÉÅ ÎÇòÌÉÄÎÇú ÏùºÎ∂Ä Ï°∞Î¨∏ Î∞è Ïö©Ïñ¥Ïùò ÎØ∏ÎπÑÏ†êÏùÑ Ï†ïÎπÑÌïòÍ∏∞ ÏúÑÌï¥ Ï†úÏïàÎê®. Ìï¥Îãπ ÏïàÍ±¥ÏùÄ Í∞ÄÍ≤∞Îê®.\n",
            "   2  Í∂åÏó≠Î≥ÑÎ°ú ÏûàÎäî Ï§ëÍ≥†Îì±ÌïôÍµêÎèÑ Î™ÖÎ¨∏ÏùÑ ÎßåÎì§Í∏∞ ÏúÑÌï¥ÏÑú Íµ∞ÏóêÏÑúÎèÑ ÏßÄÏó≠Í≥º Í∑†ÌòïÏùÑ ÎßûÏ∂ú Í≤É.\n",
            "   3  Ï†ú208Ìöå ÏûÑÏãúÌöå Ìú¥ÌöåÏùò Í±¥ÏùÄ ÌöåÍ∏∞ Ï§ë Ï¶ùÌèâ, ÏßÑÏ≤ú, Í¥¥ÏÇ∞, ÏùåÏÑ± Íµ≠ÌöåÏùòÏõê Î≥¥Í∂êÏÑ†Í±∞Î°ú Ìú¥ÌöåÌï®.\n",
            "   4  Ï†ú40Ìöå Ï≤≠Ï£ºÏãúÏùòÌöå(ÏûÑÏãúÌöå)Ïùò ÌöåÍ∏∞Îäî 2Ïõî 18ÏùºÎ∂ÄÌÑ∞ 2Ïõî 22ÏùºÍπåÏßÄ 5ÏùºÍ∞ÑÏúºÎ°ú Í∞ÄÍ≤∞Îê®.\n",
            "   5  ÏïàÏ†ÑÏ¥ùÍ¥ÑÍ≥º ÏÜåÍ¥Ä Ï£ºÏöîÏóÖÎ¨¥ Î≥¥Í≥†.\n",
            "   6  Ï†ú214Ìöå ÏôÑÏ£ºÍµ∞ÏùòÌöå ÏûÑÏãúÌöå Ï†ú1Ï∞® Î≥∏ÌöåÏùò Í∞úÏùò ÏÑ†Ìè¨.\n",
            "   7  ÏùåÏÑ±Íµ∞Í∞ÑÏù¥ÏÉÅÏàòÎèÑÍ¥ÄÎ¶¨Ï°∞Î°ÄÍ∞úÏ†ïÏ°∞Î°ÄÏïàÏùÄ ÏàòÎèÑÎ≤ïÏùò Í∞úÏ†ïÏúºÎ°ú ÏùºÏ†ïÍ∑úÎ™® ÎØ∏ÎßåÏù∏ ÏãúÏÑ§ÏùÑ ÏÜåÍ∑úÎ™® Í∏âÏàòÏãúÏÑ§Î°ú Î∂ÑÎ•òÌï®Ïóê Îî∞Îùº Í∏∞Ï°¥Ïùò ÏùåÏÑ±Íµ∞Í∞ÑÏù¥ÏÉÅÏàòÎèÑÍ¥ÄÎ¶¨Ï°∞Î°ÄÎ•º Í∞úÏ†ï Î≤ïÎ†πÏùò ÎÇ¥Ïö©Ïóê Î∂ÄÌï©ÎêòÍ≤å Í∞úÏ†ïÌïòÏó¨ Í∞ÑÏù¥ÏÉÅÏàòÎèÑ Î∞è ÏÜåÍ∑úÎ™®Í∏âÏàòÏãúÏÑ§ÏùÑ Î≥¥Îã§ Ìö®Ïú®Ï†ÅÏúºÎ°ú Í¥ÄÎ¶¨ÌïòÍ∏∞ ÏúÑÌï¥ Ï†úÏïàÎê®. Ìï¥Îãπ ÏïàÍ±¥ÏùÄ Í∞ÄÍ≤∞Îê®.\n",
            "   8  Ï†ú226Ìöå ÏôÑÏ£ºÍµ∞ÏùòÌöå Ï†ú2Ï∞® Ï†ïÎ°ÄÌöå Ï†ú2Ï∞® Î≥∏ÌöåÏùò Í∞úÏùò ÏÑ†Ìè¨.\n",
            "   9  Í∑†ÌòïÍ∞úÎ∞úÍ≥º ÏÜåÍ¥Ä Ï£ºÏöî ÌòÑÏïàÏÇ¨ÏóÖ Î≥¥Í≥†.\n",
            "  10  2014ÎÖÑÎèÑ Ï†ú2Ï∞® ÏàòÏãúÎ∂Ñ Í≥µÏú†Ïû¨ÏÇ∞ Í¥ÄÎ¶¨Í≥ÑÌöçÏïàÏùÄ ÏùåÏÑ±Ïùç Ï≤≠ÏÇ¨Î•º Ïã†Ï∂ïÌïòÍ∏∞ ÏúÑÌï¥ Í≥µÏú†Ïû¨ÏÇ∞ Ï∑®Îìù Í≥ÑÌöçÏùÑ ÏùºÎ∂Ä Î≥ÄÍ≤Ω Ï∂îÏßÑÌïòÍ≥†Ïûê ÌïòÎäî Í≤ÉÏúºÎ°ú Ìï¥Îãπ ÏïàÍ±¥ÏùÄ Í∞ÄÍ≤∞Îê®. ÏùåÏÑ±Íµ∞ Ïû¨ÏÇ∞ÏÑ∏ ÎèÑÏãúÏßÄÏó≠Î∂Ñ Ï†ÅÏö©ÎåÄÏÉÅÏßÄÏó≠ Î≥ÄÍ≤ΩÍ≥†ÏãúÏïàÏùÄ ÏùåÏÑ±Íµ∞ ÎèÑÏãúÏßÄÏó≠ Î≥ÄÍ≤ΩÏóê Îî∞Îùº Ïû¨ÏÇ∞ÏÑ∏ ÎèÑÏãúÏßÄÏó≠Î∂Ñ Ï†ÅÏö©ÎåÄÏÉÅÏßÄÏó≠ÏùÑ Î≥ÄÍ≤ΩÌïòÏó¨ Í≥†ÏãúÌïòÍ≥†Ïûê Ï†úÏïàÌï®.\n",
            "  11  Ï†ú193Ìöå ÏùåÏÑ±Íµ∞ÏùòÌöå ÏûÑÏãúÌöåÏùò ÌöåÍ∏∞Îäî 7Ïõî 7Ïùº ÌïòÎ£®Î°ú Í∞ÄÍ≤∞Îê®.\n",
            "  12  ÏùåÏÑ±Íµ∞ Ï£ºÏöîÏÇ¨ÏóÖ ÌòÑÏßÄÌôïÏù∏ ÌäπÎ≥ÑÏúÑÏõêÌöå Íµ¨ÏÑ±ÏïàÏùÄ ÏùåÏÑ±Íµ∞Ïùò ÌòÑÏïàÏÇ¨ÏóÖÍ≥º 2010ÎÖÑÎèÑ ÌñâÏ†ïÏÇ¨Î¨¥Í∞êÏÇ¨ Ïãú ÏßÄÏ†ÅÎêú ÏÇ¨ÏóÖ, Íµ¨Ï†úÏó≠ Îß§Î™∞ÏßÄÏóê ÎåÄÌïú ÌòÑÏßÄÌôïÏù∏, ÏÇ¨ÏóÖÏùò Ï∂îÏßÑÏÇ¨Ìï≠ÏùÑ Ï†êÍ≤ÄÌïòÏó¨ Î∂ÄÏã§Í≥µÏÇ¨Î•º ÏÇ¨Ï†ÑÏóê ÏòàÎ∞©ÌïòÍ≥† ÏÇ¨ÏóÖÏòàÏÇ∞Ïù¥ ÌïÑÏöîÌïú Í≥≥Ïóê Ï†ÅÏ†àÌûà Ïì∞Ïùº Ïàò ÏûàÎèÑÎ°ù Ï£ºÏöîÏÇ¨ÏóÖ ÌòÑÏßÄÌôïÏù∏ ÌäπÎ≥ÑÏúÑÏõêÌöåÎ•º Íµ¨ÏÑ±ÌïòÍ≥†Ïûê Ìï®. Ï£ºÏöîÏÇ¨ÏóÖ ÌòÑÏßÄÌôïÏù∏ ÌäπÎ≥ÑÏúÑÏõêÌöå ÏúÑÏõêÏùÄ ÏÜêÏàòÏ¢Ö ÏùòÏõê, Ïù¥ÌïúÏ≤† ÏùòÏõê, ÎÇ®Í∂ÅÏú† ÏùòÏõê, Ï°∞Ï≤úÌù¨ ÏùòÏõê, ÏÜêÎã¨ÏÑ≠ ÏùòÏõê, Ïù¥ÎåÄÏõÖ ÏùòÏõê, ÍπÄÏàúÏò• ÏùòÏõêÏúºÎ°ú Íµ¨ÏÑ±ÌïòÍ≥†Ïûê Ìï®. Ìï¥Îãπ Í≤∞ÏùòÏïàÏùÄ Í∞ÄÍ≤∞ÎêòÏóàÏùå.\n",
            "  13  ÏùåÏÑ±Íµ∞ Ï†ÄÏÜåÎìùÏ£ºÎØºÏûêÎÖÄ Ïû•ÌïôÍ∏à ÏßÄÍ∏â Ï°∞Î°Ä Ï†ÑÎ∂ÄÍ∞úÏ†ïÏ°∞Î°ÄÏïàÏùÄ Ï†ÄÏÜåÎìùÏ∏µ Î≤îÏúÑ ÏôÑÌôî, Ïû•ÌïôÍ∏à ÏßÄÍ∏âÎåÄÏÉÅÏûê ÌôïÎåÄ Î∞è ÏÑ±Ï†ÅÏû•ÌïôÍ∏à Ï†úÏô∏ Îì± Ïû•ÌïôÍ∏à ÏßÄÍ∏â Í∏∞Ï§ÄÏùÑ Ï°∞Ï†ïÌïòÍ≥† ÏïåÍ∏∞ Ïâ¨Ïö¥ Î≤ïÎ†π Ï†ïÎπÑ Í∏∞Ï§ÄÏóê Îî∞ÎùºÏÑú Î∂àÌï©Î¶¨Ìïú Ï°∞Î¨∏ÏùÑ Ï†ïÎπÑÌïòÍ∏∞ ÏúÑÌïòÏó¨ Î≥∏ Ï°∞Î°ÄÎ•º Ï†ÑÎ∂ÄÍ∞úÏ†ï ÌïòÎ†§Í≥† Î∞úÏùòÌï®. Ìï¥Îãπ ÏïàÍ±¥ÏùÄ Í∞ÄÍ≤∞Îê®. ÏùåÏÑ±Íµ∞ ÏßÄÏó≠ÏïÑÎèôÏÑºÌÑ∞ Ïö¥ÏòÅ Î∞è ÏßÄÏõêÏóê Í¥ÄÌïú Ï°∞Î°ÄÏïàÏùÄ Î∞©Í≥º ÌõÑ ÎèåÎ¥ÑÏù¥ ÌïÑÏöîÌïú ÏßÄÏó≠ÏÇ¨Ìöå ÏïÑÎèôÏùò Í±¥Ï†ÑÌïú Ïù∏Í≤©Î∞úÎã¨Í≥º Ï†ïÏÑúÌï®ÏñëÏùÑ ÌÜµÌïòÏó¨ Í±¥Í∞ïÍ≥º Î≥µÏßÄÏ¶ùÏßÑÏùÑ ÎèÑÎ™®ÌïòÍ∏∞ ÏúÑÌï¥ Î∞úÏùòÌï®.\n",
            "  14  Ï†ú66Ìöå ÏôÑÏ£ºÍµ∞ÏùòÌöå ÏûÑÏãúÌöå Ï†ú1Ï∞® Î≥∏ÌöåÏùò Í∞úÏùò ÏÑ†Ìè¨.\n",
            "  15  2018ÎÖÑÎèÑ Ï£ºÏöîÏóÖÎ¨¥ Î≥¥Í≥†Ïùò Í±¥ÏùÄ Í±¥ÏÑ§ÍµêÌÜµÍ≥º, ÎèÑÏãúÍ≥º, ÏÇ∞ÏóÖÍ∞úÎ∞úÍ≥º, Í±¥Ï∂ïÌóàÍ∞ÄÍ≥º ÏàúÏúºÎ°ú Î≥¥Í≥† ÏßÑÌñâÌï®.\n"
          ]
        }
      ],
      "source": [
        "print(\n",
        "    tabulate(\n",
        "        zip(\n",
        "            range(len(summaries_after_tuning)),\n",
        "            summaries_after_tuning,\n",
        "        ),\n",
        "        headers=[\"Id\", \"Summary after\"],\n",
        "    )\n",
        ")\n",
        "print(\"\\nTarget summaries:\\n\")\n",
        "print(\n",
        "    tabulate(list(enumerate(test_samples[\"summary\"])), headers=[\"Id\", \"Target summary\"])\n",
        ")\n",
        "# print(\"\\nSource documents:\\n\")\n",
        "# print(tabulate(list(enumerate(test_samples[\"context\"])), headers=[\"Id\", \"context\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zV4eO9G1frHQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "sk",
      "language": "python",
      "name": "sk"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}