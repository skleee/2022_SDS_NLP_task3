{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8VR8kd4ipPN"
      },
      "source": [
        "# KoBART fine-tuning 파이썬노트북 버전입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "train.json, test.json이 포함된 `data/` 폴더와 같은 레벨에 있다고 가정합니다.\n",
        "\n",
        "   ├ main_trainer.ipynb<br>\n",
        ".. └ data<br>\n",
        ".... ├ train.json<br>\n",
        ".... ├ test.json<br>\n",
        ".... └ sample_submission.csv<br>"
      ],
      "metadata": {
        "id": "uBQoX_uyrJrk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfUrYcjmiRNg",
        "outputId": "61b9dd59-d57c-4f80-e721-3fa80c7d6ff3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# git clone을 통해 가져온 2022_SDS_NLP_task3 폴더 내에 위치하도록 경로를 이동합니다.\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/2022_SDS_NLP_task3')  # 경로에 맞게 수정해주세요"
      ],
      "metadata": {
        "id": "9CaVs09Ej_R8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUbndtirkBY9",
        "outputId": "470e6be7-aeee-47ea-d19a-fb7bfa979ffa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.Data_EDA.ipynb   data\t\t       main_trainer.py\tutils.py\n",
            "2.Tokenizer.ipynb  logs\t\t       README.md\n",
            "3.Inference.ipynb  main_trainer.ipynb  results\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_gaaojSBoQ5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "589dfa4e-5dee-4236-8c8b-543361f876e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.22.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.9.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.5.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.12.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.9.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.8.2)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.1.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.6.15)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.97)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.7/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.2.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from rouge_score) (3.7)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk->rouge_score) (4.64.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->rouge_score) (7.1.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk->rouge_score) (2022.6.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->rouge_score) (1.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (0.8.10)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: asian-bart in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from asian-bart) (1.12.1+cu113)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from asian-bart) (0.1.97)\n",
            "Requirement already satisfied: transformers>=4 in /usr/local/lib/python3.7/dist-packages (from asian-bart) (4.22.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers>=4->asian-bart) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers>=4->asian-bart) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4->asian-bart) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4->asian-bart) (3.8.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4->asian-bart) (0.9.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=4->asian-bart) (4.12.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=4->asian-bart) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=4->asian-bart) (1.21.6)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=4->asian-bart) (0.12.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=4->asian-bart) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers>=4->asian-bart) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers>=4->asian-bart) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=4->asian-bart) (3.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4->asian-bart) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4->asian-bart) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4->asian-bart) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4->asian-bart) (3.0.4)\n"
          ]
        }
      ],
      "source": [
        "! pip install transformers\n",
        "! pip install datasets\n",
        "! pip install sentencepiece\n",
        "! pip install rouge_score\n",
        "! pip install tabulate\n",
        "! pip install asian-bart"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHlRNvK1frHH"
      },
      "source": [
        "## 필요한 라이브러리, 패키지 임포트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rimUDCQGoTAJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "import nltk\n",
        "import random\n",
        "import datasets\n",
        "import argparse\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "\n",
        "from transformers import (\n",
        "    Seq2SeqTrainingArguments,\n",
        "    Seq2SeqTrainer,\n",
        "    DataCollatorForSeq2Seq,\n",
        "    BartForConditionalGeneration, \n",
        "    PreTrainedTokenizerFast\n",
        ") \n",
        "from tqdm import tqdm\n",
        "\n",
        "from IPython import embed\n",
        "from time import strftime\n",
        "from tabulate import tabulate\n",
        "\n",
        "\n",
        "# 데이터셋 관련 패키지\n",
        "import pyarrow as pa\n",
        "import pyarrow.dataset as ds\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "# from torch.utils.data import Dataset\n",
        "\n",
        "import os\n",
        "\n",
        "\n",
        "os.environ['WANDB_DISABLED'] = 'true'\n",
        "\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(0)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDQoYrz9frHI"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed: int):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed) # Multi GPU\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.enabled = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJO4TovGfrHJ"
      },
      "source": [
        "## 하이퍼파라미터 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lglyAqo2frHJ"
      },
      "outputs": [],
      "source": [
        "seed = 42\n",
        "\n",
        "model_backbone = 'kobart_base'\n",
        "model_pretrained = 'gogamza/kobart-base-v2'\n",
        "data_dir =  'data'\n",
        "output_dir = 'checkpoint'\n",
        "result_dir = 'results'\n",
        "\n",
        "lr = 1e-5\n",
        "wr = 0.0\n",
        "wd = 0.01\n",
        "\n",
        "train_batch_size = 16\n",
        "test_batch_size = 4\n",
        "num_train_epochs = 10\n",
        "encoder_max_length = 512\n",
        "decoder_max_length = 64\n",
        "label_smoothing = 0.0\n",
        "\n",
        "stratify = True\n",
        "test_size = 0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_WqAg9efrHK"
      },
      "outputs": [],
      "source": [
        "set_seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOFGjG4WfrHK"
      },
      "source": [
        "## 로그 폴더 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7cZQZbPfrHK"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "0. Set log dir\n",
        "'''\n",
        "log_dir = os.path.join(result_dir, model_backbone)\n",
        "\n",
        "if not os.path.exists(log_dir):\n",
        "    os.makedirs(log_dir)\n",
        "\n",
        "log_dirs = os.listdir(log_dir)\n",
        "\n",
        "if len(log_dirs) == 0:\n",
        "    idx = 0\n",
        "else:\n",
        "    idx_list = sorted([int(d.split('_')[0]) for d in log_dirs])\n",
        "    idx = idx_list[-1] + 1\n",
        "\n",
        "cur_log_dir = '%d_%s' % (idx, strftime('%Y%m%d-%H%M'))\n",
        "full_log_dir = os.path.join(log_dir, cur_log_dir)\n",
        "\n",
        "if not os.path.exists(full_log_dir):\n",
        "    os.mkdir(full_log_dir)\n",
        "\n",
        "output_dir = os.path.join(full_log_dir, output_dir)\n",
        "\n",
        "final_result = {}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioBCSmk0frHL"
      },
      "source": [
        "## 모델, 토크나이저 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGtlNKAgfrHL",
        "outputId": "5fa37f55-fff6-4503-bbfa-12db5a239575"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BartConfig {\n",
            "  \"_name_or_path\": \"gogamza/kobart-base-v2\",\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": false,\n",
            "  \"architectures\": [\n",
            "    \"BartModel\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
            "  \"bos_token_id\": 1,\n",
            "  \"classif_dropout\": 0.1,\n",
            "  \"classifier_dropout\": 0.1,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 3072,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 1,\n",
            "  \"do_blenderbot_90_layernorm\": false,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 3072,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 6,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"extra_pos_embeddings\": 2,\n",
            "  \"force_bos_token_to_be_generated\": false,\n",
            "  \"forced_eos_token_id\": 1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEGATIVE\",\n",
            "    \"1\": \"POSITIVE\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"kobart_version\": 2.0,\n",
            "  \"label2id\": {\n",
            "    \"NEGATIVE\": 0,\n",
            "    \"POSITIVE\": 1\n",
            "  },\n",
            "  \"max_position_embeddings\": 1026,\n",
            "  \"model_type\": \"bart\",\n",
            "  \"normalize_before\": false,\n",
            "  \"normalize_embedding\": true,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 3,\n",
            "  \"scale_embedding\": false,\n",
            "  \"static_position_embeddings\": false,\n",
            "  \"tokenizer_class\": \"PreTrainedTokenizerFast\",\n",
            "  \"transformers_version\": \"4.22.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30000\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download model and tokenizer\n",
        "\n",
        "if model_pretrained == 'kykim/bertshared-kor-base':\n",
        "    from transformers import BertTokenizerFast, EncoderDecoderModel\n",
        "    tokenizer = BertTokenizerFast.from_pretrained(\"kykim/bertshared-kor-base\", model_max_length=512)\n",
        "    model = EncoderDecoderModel.from_pretrained(\"kykim/bertshared-kor-base\")\n",
        "    \n",
        "    model.config.min_length = None\n",
        "    model.config.decoder_start_token_id = tokenizer.cls_token_id\n",
        "    model.config.pad_token_id = tokenizer.pad_token_id\n",
        "    model.config.vocab_size = model.config.decoder.vocab_size\n",
        "    \n",
        "\n",
        "elif model_pretrained == 'hyunwoongko/asian-bart-ecjk':\n",
        "    # 라이브러리 설치가 필요합니다. (pip install asian-bart)\n",
        "    from asian_bart import AsianBartTokenizer, AsianBartForConditionalGeneration\n",
        "    tokenizer = AsianBartTokenizer.from_pretrained(\"hyunwoongko/asian-bart-ecjk\")\n",
        "    model = AsianBartForConditionalGeneration.from_pretrained(\"hyunwoongko/asian-bart-ecjk\")\n",
        "\n",
        "elif model_pretrained == 'paust/pko-t5-base':\n",
        "    from transformers import T5TokenizerFast, T5ForConditionalGeneration\n",
        "    tokenizer = T5TokenizerFast.from_pretrained('paust/pko-t5-base')\n",
        "    model = T5ForConditionalGeneration.from_pretrained('paust/pko-t5-base')\n",
        "\n",
        "elif model_pretrained == 'facebook/mbart-large-50':\n",
        "    from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
        "    model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50\")\n",
        "    tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50\", src_lang=\"ko_KR\", tgt_lang=\"ko_KR\")\n",
        "\n",
        "elif model_pretrained in ['gogamza/kobart-base-v1', 'cosmoquester/bart-ko-mini', 'gogamza/kobart-summarization', 'gogamza/kobart-base-v2']:\n",
        "    tokenizer = PreTrainedTokenizerFast.from_pretrained(model_pretrained)\n",
        "    # Default pre-trained model is from https://github.com/seujung/KoBART-summarization \n",
        "    model = BartForConditionalGeneration.from_pretrained(model_pretrained)\n",
        "\n",
        "else:\n",
        "    print(f\"Model {model_pretrained} is not supported\")\n",
        "    exit()\n",
        "\n",
        "print(model.config)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yD2_hzYbfrHM"
      },
      "source": [
        "## 2. 데이터셋 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-o-c4XxfrHM",
        "outputId": "c5975e0a-f63a-4407-a563-7f6222faba3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163,
          "referenced_widgets": [
            "d3640eda68d54a168d6a31027ee44768",
            "52a6b7e54b6e4891b5cfa47ea1e7308e",
            "f96370c72aa84400a0456f2ac81698e4",
            "0ed62bec5c144035b905be94a8f5d3da",
            "b5d0719e86b14edb8830a53e232ecce2",
            "7f2f0ab591064800b6c24a503c1c7b9c",
            "b368dfc422804fd3a3917f8221660d2c",
            "49a641b102914a759f96cb7cbe46bb79",
            "66c28bbc85cc4015a75e85dc3712bdcf",
            "dec16cdf0a8140d2b6f04906a7a9af15",
            "f584d826a168464aa1d47c9b5dbea71b",
            "5ab60cfd4b2a426f82c893be1a815203",
            "0483d7b3b90d45e88ac707a924dbd170",
            "9f366acaff344c80ab586613da27f6d2",
            "e070ed9f13904c0fb53a4b1dbac3f321",
            "f569bebd37134707a6e10ce0b64f1649",
            "364edffa798a4b9a971cd06f14509192",
            "845555896f0e43958f33f38149186916",
            "efe1a7b1ffca4c7e844d6f18e472ce60",
            "b98ac0bf3df64b94a3f695c70d03339e",
            "c70e564e7ddc4e1181a128e150a5a739",
            "a2b55de46eee4200952b026d35d46e61",
            "a98af225353c48a8b43205064aea3234",
            "a1deb16caf5244118a3f9df48f23a6e2",
            "c84c93495f274eb093980a02bb57d7e1",
            "9821a46e202d4bbda0e600cde6c159c2",
            "a9ea1107dbf84d82aef30ec37d093ff1",
            "f2ff567d035c442abe226f3814b695e0",
            "9933d8b8b6684b18b70798d9bfaf6c2e",
            "8994d7f332684213b67b6abad31b5a51",
            "5f9f9ac49f9e4898b876ae53c0fe01fb",
            "368e41f4be0948d98e97f00cad1cad4f",
            "85a547eaffd049df81b587ba9cc4cb59",
            "0f8a2d72d83245feb9092cef980e21a6",
            "1e444421e291499090646c32eb11b5d7",
            "f02387bad44745d09e8407d85edb9c59",
            "820dcb1d25dd43fcba7dfc39c025a8a2",
            "6b517637c8574946b8588df827deb556",
            "4159fe7e3c1941629fa1a1a1531ae09f",
            "82c97943fce749d9be041f9578c15354",
            "57909452e375416a9b0bb8ee5da71134",
            "4811f98ed07942b19c0dbfd4c0189d3c",
            "26622b46bde047e8892da9105baac32b",
            "7ac7202754db4e8388581ace19c9cb9a"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Loading data from data\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Casting to class labels:   0%|          | 0/3 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d3640eda68d54a168d6a31027ee44768"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Casting the dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ab60cfd4b2a426f82c893be1a815203"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Casting to class labels:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a98af225353c48a8b43205064aea3234"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Casting the dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f8a2d72d83245feb9092cef980e21a6"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "print(f\"> Loading data from {data_dir}\")\n",
        "TRAIN_SOURCE = os.path.join(data_dir, \"train.json\")\n",
        "TEST_SOURCE = os.path.join(data_dir, \"test.json\")\n",
        "\n",
        "with open(TRAIN_SOURCE) as f:\n",
        "    TRAIN_DATA = json.loads(f.read())\n",
        "    \n",
        "with open(TEST_SOURCE) as f:\n",
        "    TEST_DATA = json.loads(f.read())\n",
        "\n",
        "train = pd.DataFrame(columns=['uid', 'title', 'region', 'context', 'summary'])\n",
        "uid = 1000\n",
        "for data in TRAIN_DATA:\n",
        "    for agenda in data['context'].keys():\n",
        "        context = ''\n",
        "        for line in data['context'][agenda]:\n",
        "            context += data['context'][agenda][line]\n",
        "            context += ' '\n",
        "        train.loc[uid, 'uid'] = uid\n",
        "        train.loc[uid, 'title'] = data['title']\n",
        "        train.loc[uid, 'region'] = data['region']\n",
        "        train.loc[uid, 'context'] = context[:-1]\n",
        "        train.loc[uid, 'summary'] = data['label'][agenda]['summary']\n",
        "        uid += 1\n",
        "\n",
        "test = pd.DataFrame(columns=['uid', 'title', 'region', 'context'])\n",
        "uid = 2000\n",
        "for data in TEST_DATA:\n",
        "    for agenda in data['context'].keys():\n",
        "        context = ''\n",
        "        for line in data['context'][agenda]:\n",
        "            context += data['context'][agenda][line]\n",
        "            context += ' '\n",
        "        test.loc[uid, 'uid'] = uid\n",
        "        test.loc[uid, 'title'] = data['title']\n",
        "        test.loc[uid, 'region'] = data['region']\n",
        "        test.loc[uid, 'context'] = context[:-1]\n",
        "        uid += 1\n",
        "\n",
        "if stratify:\n",
        "    # https://dacon.io/competitions/official/235813/codeshare/3719?page=1&dtype=recent 참고\n",
        "    # context 토큰 길이 \n",
        "    def token_len(text):\n",
        "        return len(tokenizer.tokenize(text))\n",
        "\n",
        "    # context의 내용을 안건 상정, 의원 발언 요약, 부서 보고, 기타로 러프하게 분류\n",
        "    def type_classifier(context):\n",
        "        if '보임' in context[:1000]:\n",
        "            return '의원 보임'\n",
        "        elif (len(context.split('의원님 질')) > 2 and len(tokenizer.tokenize(context)) > 1024 and '상정' not in context[:200]):#and '보고' not in summary[-3:]:\n",
        "            return '의원 발언 요약' \n",
        "        elif '자유발언' in context[:200] and len(context.split('의원님 나')) > 1:\n",
        "            return '자유발언'\n",
        "        elif '상정' in context[:200]:\n",
        "            return '안건 상정'\n",
        "        elif '개의' in context[:100]:\n",
        "            return '개의 선포'\n",
        "        elif '보고' in context[:200]:\n",
        "            return '부서 보고'\n",
        "        else:\n",
        "            return '기타' \n",
        "\n",
        "    # train,test에 본문 토큰 길이와 러프한 내용 분류 추가\n",
        "    train['con_token_len'] = train['context'].apply(token_len)\n",
        "    train['con_type'] = train['context'].apply(type_classifier)\n",
        "\n",
        "    test['con_token_len'] = test['context'].apply(token_len)\n",
        "    test['con_type'] = test['context'].apply(type_classifier)\n",
        "\n",
        "    # convert to Huggingface dataset\n",
        "    train = train[['context', 'summary', 'con_type']]\n",
        "    test = test[['context', 'con_type']]\n",
        "\n",
        "    train_dataset = Dataset(pa.Table.from_pandas(train))\n",
        "    test_dataset = Dataset(pa.Table.from_pandas(test))\n",
        "\n",
        "    train_dataset = train_dataset.class_encode_column(\"con_type\")\n",
        "    test_dataset = test_dataset.class_encode_column(\"con_type\")\n",
        "    \n",
        "    try:\n",
        "        train_dataset = train_dataset.remove_columns('__index_level_0__')\n",
        "        test_dataset = test_dataset.remove_columns('__index_level_0__')\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    train_data, eval_data = train_dataset.train_test_split(test_size=test_size, shuffle=True, seed=seed, stratify_by_column='con_type').values()\n",
        "\n",
        "else:\n",
        "    # convert to Huggingface dataset\n",
        "    train = train[['context', 'summary']]\n",
        "    test = test[['context']]\n",
        "\n",
        "    train_dataset = Dataset(pa.Table.from_pandas(train))\n",
        "    test_dataset = Dataset(pa.Table.from_pandas(test))\n",
        "\n",
        "    try:\n",
        "        train_dataset = train_dataset.remove_columns('__index_level_0__')\n",
        "        test_dataset = test_dataset.remove_columns('__index_level_0__')\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    train_data, eval_data = train_dataset.train_test_split(test_size=test_size, shuffle=True, seed=seed).values()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tC7qIpyQfrHN",
        "outputId": "e579f9eb-af96-413d-e11f-f4024eb9f0b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Number of train data: 2395, eval data: 599, test data: 506\n"
          ]
        }
      ],
      "source": [
        "train_data, eval_data, test_data = train_data, eval_data, test_dataset\n",
        "print(f'> Number of train data: {len(train_data)}, eval data: {len(eval_data)}, test data: {len(test_data)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5WxTLUZSfrHN"
      },
      "outputs": [],
      "source": [
        "# Preprocess and tokenize data\n",
        "def batch_tokenize_preprocess(batch, tokenizer, max_source_length, max_target_length):\n",
        "    source, target = batch[\"context\"], batch[\"summary\"]\n",
        "    source_tokenized = tokenizer(\n",
        "        source, padding=\"max_length\", truncation=True, max_length=max_source_length\n",
        "    )\n",
        "    target_tokenized = tokenizer(\n",
        "        target, padding=\"max_length\", truncation=True, max_length=max_target_length\n",
        "    )\n",
        "\n",
        "    batch = {k: v for k, v in source_tokenized.items()}\n",
        "    # Ignore padding in the loss\n",
        "    batch[\"labels\"] = [\n",
        "        [-100 if token == tokenizer.pad_token_id else token for token in l]\n",
        "        for l in target_tokenized[\"input_ids\"]\n",
        "    ]\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWoUXwkkfrHN",
        "outputId": "a33715f7-0f04-493d-8427-57a448163fa4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "d41d73172ea84ef09fd73345bfe1cef8",
            "80c8125faa264b49b042ca8891ccbce6",
            "149eeaa6c5d24aeba7da3870a98866a0",
            "6b7109e541aa4e08968c099585c40575",
            "1e6872b3a3d349a6bf7b3b0ae1ff8686",
            "ec2125ba9608464e9d13845632ae5af4",
            "50170699516340949752872b99f50ace",
            "880ef26cb21845edb33451899b734fc8",
            "a835a16c0b744e1fb1082d0137a3eaf0",
            "aa9d6d3334024560884c6dffa6193a1d",
            "0c2cd9e7fe0a4b14b03647f0f429c6c3",
            "59286d9fc92644a38dfe859d41d9109a",
            "b4157d95c8b041ed8dda4418d48ee3c5",
            "7f2a068f77d9454c9ddd6cf3ed8db907",
            "fb37aa3850dd4f8483e32fd6d1664c9d",
            "072da68506984e0da702264fc9c019f1",
            "917cf168a3b34d7993d1075fa323cb25",
            "ecbd69e3e95747dcb2c7660764875127",
            "8e3dfef5aaaa476ebd002ad75db8765a",
            "dca704e1ddb64e94a532d46585dd0075",
            "321b1789028d4afc8c50012184bb670e",
            "043e7e881ae54540921654a61fde4bcf"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d41d73172ea84ef09fd73345bfe1cef8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "59286d9fc92644a38dfe859d41d9109a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "train_data = train_data.map(\n",
        "    lambda batch: batch_tokenize_preprocess(\n",
        "        batch, tokenizer, encoder_max_length, decoder_max_length\n",
        "    ),\n",
        "    batched=True,\n",
        "    remove_columns=train_data.column_names,\n",
        ")\n",
        "\n",
        "validation_data = eval_data.map(\n",
        "    lambda batch: batch_tokenize_preprocess(\n",
        "        batch, tokenizer, encoder_max_length, decoder_max_length\n",
        "    ),\n",
        "    batched=True,\n",
        "    remove_columns=eval_data.column_names,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNkb4wwbfrHO"
      },
      "source": [
        "## 2. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZpRKt5mfrHO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "edc5b44a2f5b455a9aebb020f1c8be74",
            "707cab4823b543b7b0bc054e506b31ea",
            "a1ee30fd88224f4d95d24a762c9bface",
            "7bd79da3c1c6490d865e573a27852a9f",
            "713c983339ca4253b30a80e8a29517dd",
            "b4db5e9c07fe4162a04e9ec10a2179a8",
            "05373960af684a7aa65cbd16357a173f",
            "e81e7f052dfc4441b8cd03ff89e9acb7",
            "2390c3e9c1914834b91919f3f8183b6e",
            "d5dd92a7cb03490e80006afe6a76488b",
            "b2a57cb7ab5d403ba900773e168c8f11"
          ]
        },
        "outputId": "0cdd4755-b719-4660-9ea5-cfd391076e1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/2.16k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "edc5b44a2f5b455a9aebb020f1c8be74"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Borrowed from https://github.com/huggingface/transformers/blob/master/examples/seq2seq/run_summarization.py\n",
        "\n",
        "nltk.download(\"punkt\", quiet=True)\n",
        "metric = datasets.load_metric(\"rouge\")\n",
        "\n",
        "def postprocess_text(preds, labels):\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [label.strip() for label in labels]\n",
        "\n",
        "    # rougeLSum expects newline after each sentence\n",
        "    preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n",
        "    labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n",
        "\n",
        "    return preds, labels\n",
        "\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "    # Replace -100 in the labels as we can't decode them.\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Some simple post-processing\n",
        "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
        "\n",
        "    result = metric.compute(\n",
        "        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n",
        "    )\n",
        "    # Extract a few results from ROUGE\n",
        "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
        "\n",
        "    prediction_lens = [\n",
        "        np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds\n",
        "    ]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    result = {k: round(v, 4) for k, v in result.items()}\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_train_epochs = 1"
      ],
      "metadata": {
        "id": "NxnpM4kolTOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMNFG1cWfrHO",
        "outputId": "a5e7a785-2b12-430b-9739-82b9698262de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        }
      ],
      "source": [
        "# Training arguments\n",
        "# Details; https://huggingface.co/docs/transformers/main_classes/trainer#transformers.Seq2SeqTrainingArguments\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    report_to=None,\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    predict_with_generate=True,\n",
        "    output_dir=output_dir,\n",
        "    num_train_epochs=num_train_epochs,  \n",
        "    per_device_train_batch_size=train_batch_size,  \n",
        "    per_device_eval_batch_size=test_batch_size,\n",
        "    learning_rate=lr,\n",
        "    weight_decay=wd,\n",
        "    label_smoothing_factor=label_smoothing,\n",
        "    logging_dir=\"logs\",\n",
        "    save_total_limit=3,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\", \n",
        "    greater_is_better=False,\n",
        "    save_strategy='epoch',\n",
        "    evaluation_strategy='epoch',\n",
        "    # metric_for_best_model=\"eval_rouge1\", \n",
        "    # greater_is_better=True,\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "\n",
        "# Details; https://huggingface.co/docs/transformers/main_classes/trainer#transformers.Seq2SeqTrainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=validation_data,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LS7u6QRDfrHO",
        "outputId": "7f635621-8ff2-4067-cbe9-b012713da9cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 599\n",
            "  Batch size = 4\n",
            "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [150/150 00:48]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Evaluate before fine-tuning\n",
        "trainer.evaluate()\n",
        "final_result.update({'before_fine_tuning': trainer.state.log_history})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDB06qmBfrHP",
        "outputId": "4afdb600-acb2-465e-b504-60a2c17c6bef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the training set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 2395\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 150\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [150/150 03:29, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "      <th>Gen Len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.982941</td>\n",
              "      <td>55.627300</td>\n",
              "      <td>34.633800</td>\n",
              "      <td>55.422200</td>\n",
              "      <td>55.361900</td>\n",
              "      <td>20.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 599\n",
            "  Batch size = 4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [150/150 04:11]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to results/kobart_base/2_20220928-0052/checkpoint/checkpoint-150\n",
            "Configuration saved in results/kobart_base/2_20220928-0052/checkpoint/checkpoint-150/config.json\n",
            "Model weights saved in results/kobart_base/2_20220928-0052/checkpoint/checkpoint-150/pytorch_model.bin\n",
            "tokenizer config file saved in results/kobart_base/2_20220928-0052/checkpoint/checkpoint-150/tokenizer_config.json\n",
            "Special tokens file saved in results/kobart_base/2_20220928-0052/checkpoint/checkpoint-150/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from results/kobart_base/2_20220928-0052/checkpoint/checkpoint-150 (score: 0.9829413294792175).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=150, training_loss=1.548307902018229, metrics={'train_runtime': 210.0421, 'train_samples_per_second': 11.402, 'train_steps_per_second': 0.714, 'total_flos': 730159408742400.0, 'train_loss': 1.548307902018229, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "# Train the model\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0G7OuwNNfrHP"
      },
      "source": [
        "## 3. Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVntKoNWfrHP",
        "outputId": "be4e2d06-3333-440f-dca7-33ac945373c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 599\n",
            "  Batch size = 4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [150/150 00:49]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.9829413294792175,\n",
              " 'eval_rouge1': 55.6273,\n",
              " 'eval_rouge2': 34.6338,\n",
              " 'eval_rougeL': 55.4222,\n",
              " 'eval_rougeLsum': 55.3619,\n",
              " 'eval_gen_len': 20.0,\n",
              " 'eval_runtime': 50.5554,\n",
              " 'eval_samples_per_second': 11.848,\n",
              " 'eval_steps_per_second': 2.967,\n",
              " 'epoch': 1.0}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "# Evaluate after fine-tuning\n",
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tY0WJPjLfrHP"
      },
      "outputs": [],
      "source": [
        "log_history = trainer.state.log_history\n",
        "\n",
        "with open(os.path.join(full_log_dir, f'model_{model_backbone}_lr_{lr}.json'), 'w') as f:\n",
        "    final_result.update(\n",
        "        {\n",
        "            'train_results': log_history,\n",
        "            'best_results': log_history[-1],\n",
        "        }\n",
        "    )\n",
        "    json.dump(final_result, f, indent=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPHabboifrHP"
      },
      "source": [
        "# 4. 요약문 생성 예시"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tabulate import tabulate"
      ],
      "metadata": {
        "id": "fSpDYIVqqvWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 런타임을 초기화 하지 않은 경우\n",
        "- 학습된 모델이 `model` 변수에 저장되어 있기 때문에 다시 모델을 선언하지 않으셔도 됩니다..\n",
        "- 아래 코드를 바로 실행하시면 됩니다."
      ],
      "metadata": {
        "id": "KUp5mMnHmzyj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_summary(test_samples, model):\n",
        "    inputs = tokenizer(\n",
        "        test_samples[\"context\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=encoder_max_length,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "    input_ids = inputs.input_ids.to(model.device)\n",
        "    attention_mask = inputs.attention_mask.to(model.device)\n",
        "    outputs = model.generate(input_ids, attention_mask=attention_mask, num_beams = 8, min_length = 10, max_length = 50, no_repeat_ngram_size=2)\n",
        "    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "    return outputs, output_str"
      ],
      "metadata": {
        "id": "WlAV1w7Kn2fh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test 할 샘플 텍스트를 고릅니다. (evaluation에서 선택해옵니다.)\n",
        "test_samples = eval_data.select(range(16))"
      ],
      "metadata": {
        "id": "61-sw38Hn3lI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summaries_after_tuning = generate_summary(test_samples, model)[1]"
      ],
      "metadata": {
        "id": "6X23q6t-nHKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\n",
        "    tabulate(\n",
        "        zip(\n",
        "            range(len(summaries_after_tuning)),\n",
        "            summaries_after_tuning,\n",
        "        ),\n",
        "        headers=[\"Id\", \"Summary after\"],\n",
        "    )\n",
        ")\n",
        "print(\"\\nTarget summaries:\\n\")\n",
        "print(\n",
        "    tabulate(list(enumerate(test_samples[\"summary\"])), headers=[\"Id\", \"Target summary\"])\n",
        ")\n",
        "# print(\"\\nSource documents:\\n\")\n",
        "# print(tabulate(list(enumerate(test_samples[\"context\"])), headers=[\"Id\", \"context\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seE5C35wnYe7",
        "outputId": "a3353ec8-1d78-4eaa-847a-a39e0b8e5f3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Id  Summary after\n",
            "----  -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "   0  예산결산특별위원회 위원으로는 최관식 의원, 남궁유 의원, 김우식 의원님, 고재협 의원, 김성채 의원, 진의장 의원, 이준구 의원, 이천봉 의원이 선임됨. 특별위원회 운영기간은 제2차 정례\n",
            "   1  음성군 지방세입징수포상금 지급 조례 일부개정조례안은 결손 처분된 미수액을 징수하여 세입 증대에 기여한 공무원에게 포상금을 지급하고자 제정되었으며, 해당 안건은 가결됨\n",
            "   2  기획감사실장 이장해는 2008년도 상반기 주요업무 추진실적과 2008년 하반기 주요 업무 추진계획, 특수시책 순으로 보고할 것. <표 1페이지가 되겠습니다. 지역현안사업으로 반기문 유엔사무총장님\n",
            "   3  제208회 임시회 휴회의 건은 금번 회기 중 증평ᆞ진천, 괴산ᆞ음성 국회의원 보궐선거로 휴회가 선포됨. 제4차 본회의는 29일 오후 2시부터 계속해서 2010년도 군정\n",
            "   4  제40회 청주시의회 임시회 회기는 2월 18일부터 2월 22일까지 5일간으로 가결됨. 이재길 의원 외 여덟 분으로부터 발의된 청주시장 및 관계공무원 출석요구의 건은 시정질문을 하실 의원\n",
            "   5  2016년도 재난대응 안전한국훈련. 재난안전대책본부 운영 훈련 및 현장훈련을 5월경 실시할 계획이며, 재난관리책임기관 간 공조 및 협력체제 구축에 힘쓰도록 할 것. 재난 대응 안전총괄과 소관 주요 업무\n",
            "   6  제214회 완주군의회 임시회 제1차 본회의 개의 선포. 의사팀장으로부터 의회관련사항에 대한 보고가 있을 것. 의사팀장 서남용 의원, 부의장, 상임위원장 선거에 대한 의견조율이 원만하지 않았던 관계\n",
            "   7  음성군간이상수도관리조례 일부내용을 법령과 일치하도록 정리하는 한편 간이상 수도 및 소규모급수시설에 대한 수질검사 및 시설점검을 분기 1회 이상 실시하도록 의무화함. 해당 안건은 가\n",
            "   8  제226회 완주군의회 제2차 정례회의 제2차 본회의 개의 선포. 의사팀장 이은미. 제1차 본회의 이후 의안 접수사항. 지난 11월 21일 윤수봉 의원 발의로 발의되어 본회의에 직접 부의하였음.\n",
            "   9  균형개발과 소관 주요 현안사업 보고를 마치겠습니다. 서효석 의원님 질의하여 주시기 바랍니다. 해당 안건은 음성읍 농촌 중심지 활성화사업이 내년도 12월까지 계획이 잡혀 있는데 현재 추진되고 있는 사항이 계획대로 원만\n",
            "  10  2014년도 제2차 수시분 공유재산 관리계획안과 음성군 재산세 도시지역분 적용대상지역 변경고시안은 공유재산의 취득에 앞서서 음성군의회의 의결을 받고자 제안함. 해당 안건은 가결됨.\n",
            "  11  제193회 음성군의회 임시회 회기는 7월 7일 오늘 하루동안 가결됨. (「없습니다」하는 의원 있음. 해당 의원은 없음) 의사일정을 선포함. 의사는 이의가 없으므로 가\n",
            "  12  주요사업 현지확인 특별위원회 구성 결의안은 음성군의 현안사업과 2010년도 행정사무감사 시 지적된 사업, 구제역 매몰지에 대하여 현지확인을 하고, 사업의 추진사항을 점검하여 부실공사를 사전에 예방하고 사업예산이\n",
            "  13  음성군 저소득주민자녀 장학금 지급 조례 전부개정조례안은 저소득층 범위를 확대하여 저소득층 자녀 중 모범적인 학생, 예ᆞ체능 특기생이 포함되도록 지급대상자를 확대 추가하고, 안 제8조에는 장학생\n",
            "  14  제66회 완주군의회 임시회 제1차 본회의 개의 선포. 해당 안건은 처리하기 위한 집회 요구가 있어 가결됨. '99년 1월 27일 이진철 의원 외 6인으로부터 완주자군제증명등 수수료\n",
            "  15  2018년도 주요업무 보고의 건이 상정됨. 오늘은 건설교통과, 도시과, 산업개발과, 건축허가과 순으로 보고를 받겠습니다. 가창 안건은 상정. 가결. 건축허가의 건을 상정합니다. 가건 안건 상정\n",
            "\n",
            "Target summaries:\n",
            "\n",
            "  Id  Target summary\n",
            "----  -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "   0  예산결산 특별위원회는 최관식 의원, 남궁유 의원, 김우식 의원, 고재협 의원, 김성채 의원, 진의장 의원, 이준구 의원, 김천봉 의원으로 구성함. 특별위원회는 제2차 정례회 기간 중 의사일정에 따라서 2002년도 예산과 2001년도 제3회 추가경제예산을 심의하고자 구성함. 해당 안건은 가결됨.\n",
            "   1  음성군 지방세입징수포상금 지급 조례 일부개정조례안은 2009년 11월 1일부터 전국 자치단체 간 징수촉탁제도 운용에 따라 수탁기관이 징수촉탁으로 징수 시 교부받은 금액의 10%를 유공공무원에게 지급하여 자동차세 징수촉탁제를 활성화하고, 결손처분 미수액의 10%를 포상금으로 지급하여 결손사후관리를 위한 세무공무원의 노력 강화로 세수확충을 하며, 조례 운영 상 나타난 일부 조문 및 용어의 미비점을 정비하기 위해 제안됨. 해당 안건은 가결됨.\n",
            "   2  권역별로 있는 중고등학교도 명문을 만들기 위해서 군에서도 지역과 균형을 맞출 것.\n",
            "   3  제208회 임시회 휴회의 건은 회기 중 증평, 진천, 괴산, 음성 국회의원 보궐선거로 휴회함.\n",
            "   4  제40회 청주시의회(임시회)의 회기는 2월 18일부터 2월 22일까지 5일간으로 가결됨.\n",
            "   5  안전총괄과 소관 주요업무 보고.\n",
            "   6  제214회 완주군의회 임시회 제1차 본회의 개의 선포.\n",
            "   7  음성군간이상수도관리조례개정조례안은 수도법의 개정으로 일정규모 미만인 시설을 소규모 급수시설로 분류함에 따라 기존의 음성군간이상수도관리조례를 개정 법령의 내용에 부합되게 개정하여 간이상수도 및 소규모급수시설을 보다 효율적으로 관리하기 위해 제안됨. 해당 안건은 가결됨.\n",
            "   8  제226회 완주군의회 제2차 정례회 제2차 본회의 개의 선포.\n",
            "   9  균형개발과 소관 주요 현안사업 보고.\n",
            "  10  2014년도 제2차 수시분 공유재산 관리계획안은 음성읍 청사를 신축하기 위해 공유재산 취득 계획을 일부 변경 추진하고자 하는 것으로 해당 안건은 가결됨. 음성군 재산세 도시지역분 적용대상지역 변경고시안은 음성군 도시지역 변경에 따라 재산세 도시지역분 적용대상지역을 변경하여 고시하고자 제안함.\n",
            "  11  제193회 음성군의회 임시회의 회기는 7월 7일 하루로 가결됨.\n",
            "  12  음성군 주요사업 현지확인 특별위원회 구성안은 음성군의 현안사업과 2010년도 행정사무감사 시 지적된 사업, 구제역 매몰지에 대한 현지확인, 사업의 추진사항을 점검하여 부실공사를 사전에 예방하고 사업예산이 필요한 곳에 적절히 쓰일 수 있도록 주요사업 현지확인 특별위원회를 구성하고자 함. 주요사업 현지확인 특별위원회 위원은 손수종 의원, 이한철 의원, 남궁유 의원, 조천희 의원, 손달섭 의원, 이대웅 의원, 김순옥 의원으로 구성하고자 함. 해당 결의안은 가결되었음.\n",
            "  13  음성군 저소득주민자녀 장학금 지급 조례 전부개정조례안은 저소득층 범위 완화, 장학금 지급대상자 확대 및 성적장학금 제외 등 장학금 지급 기준을 조정하고 알기 쉬운 법령 정비 기준에 따라서 불합리한 조문을 정비하기 위하여 본 조례를 전부개정 하려고 발의함. 해당 안건은 가결됨. 음성군 지역아동센터 운영 및 지원에 관한 조례안은 방과 후 돌봄이 필요한 지역사회 아동의 건전한 인격발달과 정서함양을 통하여 건강과 복지증진을 도모하기 위해 발의함.\n",
            "  14  제66회 완주군의회 임시회 제1차 본회의 개의 선포.\n",
            "  15  2018년도 주요업무 보고의 건은 건설교통과, 도시과, 산업개발과, 건축허가과 순으로 보고 진행함.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EaHUwSYunHIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 런타임을 초기화 한 경우\n",
        "- 학습된 모델이 `model` 변수에 저장되어 있지 않기 때문에 모델, 토크나이저를 정의해야 합니다.\n",
        "- 상단 코드에서 Training 이전까지의 코드를 실행하셔야 합니다.\n",
        "- `2.Training` 바로 위 셀에서 \"런타임 -> 이전 셀 실행\"을 하시면 간편합니다.\n",
        "- 로그 폴더 설정은 training을 하지 않으시기 때문에 실행하지 않으셔도 됩니다."
      ],
      "metadata": {
        "id": "vrHesLZmnjFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_summary(test_samples, model):\n",
        "    inputs = tokenizer(\n",
        "        test_samples[\"context\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=encoder_max_length,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "    input_ids = inputs.input_ids.to(model.device)\n",
        "    attention_mask = inputs.attention_mask.to(model.device)\n",
        "    outputs = model.generate(input_ids, attention_mask=attention_mask, num_beams = 8, min_length = 10, max_length = 50,)\n",
        "    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "    return outputs, output_str"
      ],
      "metadata": {
        "id": "eIRQHYeDpwAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = 'results/kobart_base/2_20220928-0052/checkpoint/checkpoint-150' # pytorch_model.bin 등이 포함된 checkpoint path를 명시해주세요 (예시, results/kobart_base/2_20220928-0052/checkpoint/checkpoint-150 )"
      ],
      "metadata": {
        "id": "daB9Ves3pKJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download model and tokenizer\n",
        "if model_pretrained == 'kykim/bertshared-kor-base':\n",
        "    from transformers import BertTokenizerFast, EncoderDecoderModel\n",
        "    tokenizer = BertTokenizerFast.from_pretrained(\"kykim/bertshared-kor-base\", model_max_length=512)\n",
        "    model = EncoderDecoderModel.from_pretrained(checkpoint_path) # checkpoint path를 명시합니다.\n",
        "    \n",
        "    model.config.min_length = None\n",
        "    model.config.decoder_start_token_id = tokenizer.cls_token_id\n",
        "    model.config.pad_token_id = tokenizer.pad_token_id\n",
        "    model.config.vocab_size = model.config.decoder.vocab_size\n",
        "    \n",
        "\n",
        "elif model_pretrained == 'hyunwoongko/asian-bart-ecjk':\n",
        "    # 라이브러리 설치가 필요합니다. (pip install asian-bart)\n",
        "    from asian_bart import AsianBartTokenizer, AsianBartForConditionalGeneration\n",
        "    tokenizer = AsianBartTokenizer.from_pretrained(\"hyunwoongko/asian-bart-ecjk\")\n",
        "    model = AsianBartForConditionalGeneration.from_pretrained(checkpoint_path)  # checkpoint path를 명시합니다.\n",
        "\n",
        "elif model_pretrained == 'paust/pko-t5-base':\n",
        "    from transformers import T5TokenizerFast, T5ForConditionalGeneration\n",
        "    tokenizer = T5TokenizerFast.from_pretrained('paust/pko-t5-base')\n",
        "    model = T5ForConditionalGeneration.from_pretrained(checkpoint_path)  # checkpoint path를 명시합니다.\n",
        "\n",
        "elif model_pretrained == 'facebook/mbart-large-50':\n",
        "    from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
        "    model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50\")\n",
        "    tokenizer = MBart50TokenizerFast.from_pretrained(checkpoint_path, src_lang=\"ko_KR\", tgt_lang=\"ko_KR\")  # checkpoint path를 명시합니다.\n",
        "\n",
        "elif model_pretrained in ['gogamza/kobart-base-v1', 'cosmoquester/bart-ko-mini', 'gogamza/kobart-summarization', 'gogamza/kobart-base-v2']:\n",
        "    tokenizer = PreTrainedTokenizerFast.from_pretrained(model_pretrained)\n",
        "    # Default pre-trained model is from https://github.com/seujung/KoBART-summarization \n",
        "    model = BartForConditionalGeneration.from_pretrained(checkpoint_path)  # checkpoint path를 명시합니다.\n",
        "\n",
        "else:\n",
        "    print(f\"Model {model_pretrained} is not supported\")\n",
        "    exit()\n",
        "\n",
        "print(model.config)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiRhuyR-nGrD",
        "outputId": "efad8482-1c10-445a-b6bb-e3286837fc18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BartConfig {\n",
            "  \"_name_or_path\": \"results/kobart_base/2_20220928-0052/checkpoint/checkpoint-150\",\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": false,\n",
            "  \"architectures\": [\n",
            "    \"BartForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
            "  \"bos_token_id\": 1,\n",
            "  \"classif_dropout\": 0.1,\n",
            "  \"classifier_dropout\": 0.1,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 3072,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 1,\n",
            "  \"do_blenderbot_90_layernorm\": false,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 3072,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 6,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"extra_pos_embeddings\": 2,\n",
            "  \"force_bos_token_to_be_generated\": false,\n",
            "  \"forced_eos_token_id\": 1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEGATIVE\",\n",
            "    \"1\": \"POSITIVE\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"kobart_version\": 2.0,\n",
            "  \"label2id\": {\n",
            "    \"NEGATIVE\": 0,\n",
            "    \"POSITIVE\": 1\n",
            "  },\n",
            "  \"max_position_embeddings\": 1026,\n",
            "  \"model_type\": \"bart\",\n",
            "  \"normalize_before\": false,\n",
            "  \"normalize_embedding\": true,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 3,\n",
            "  \"scale_embedding\": false,\n",
            "  \"static_position_embeddings\": false,\n",
            "  \"tokenizer_class\": \"PreTrainedTokenizerFast\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.22.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30000\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2BHimCFfrHQ"
      },
      "outputs": [],
      "source": [
        "# test 할 샘플 텍스트를 고릅니다.\n",
        "test_samples = eval_data.select(range(16))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summaries_after_tuning = generate_summary(test_samples, model)[1]"
      ],
      "metadata": {
        "id": "oJ34OlokmxpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7IPtJLjCcmS",
        "outputId": "06e6cc9c-58af-4538-db09-8e10daafb981"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Id  Summary after\n",
            "----  -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "   0  의원님,님, 주신 사항으로, 예산결산특별위원회 구성안을 상정합니다. 예산결산특별위원회 구성은 여덟 분의 의원님으로 구성하도록 구성하도록 협의된 바, 사회자인 제가 특별위원회 위원을 지명하겠습니다. 의원\n",
            "   1  하여하여 설명하여 주시하여 주시하여 주시하여 주시하여 주시하여 주시하여 주시니다.니다. 재무과장입니다. 재무과장입니다. 먼저 먼저 먼저 먼저 먼저 먼저 먼저 먼저 먼저 먼저 먼저 먼저 먼저 먼저 먼저 먼저 먼저 먼저 먼저 먼저 먼저 먼저 먼저\n",
            "   2  다 다시책, 특수시책, 특수시책 순으로 보고드리겠습니다. 먼저 2008년 상반기 주요업무 추진실적입니다. 3페이지가 되겠습니다. 먼저 2008년 상반기 주요업무 추진실적입니다. 3페이지가 되겠습니다. 주요 군정추\n",
            "   3  제208회 임시회 휴회의 건은 금번 회기 중 증평ᆞ진천ᆞ괴산ᆞ괴산ᆞ음성 국회의원 보궐선거로 휴회하오니 양해하여 주시기 바랍니다. 이상으로 오늘의 계획된\n",
            "   4  제 제이 제40회 청주시의회(임시회) 회기결정의 건을 상정합니다. 이번 임시회 회기는 의회운영위원회와 협의한 바와 같이 2월 18일부터 2월 22일까지 5일간으로 하고자 하는데 의원 여러분\n",
            "   5  지 및 현장 현장 훈련 및 현장훈련을 5월경 실시할 훈련 및 현장훈련을 5월경 실시할 계획이며, 실질적 재난대응 역량강화로 안전 음성 실현과 협력체제 구축에 협력체제 구축에 힘쓰도록 하겠습니다. 먼저 3페이지\n",
            "   6  관계로 지연됐음을 양해바랍니다. 지방자치법 제63조제1항에 따라 재적의원 3분의1 이상의 의원이 출석하셨기 때문에 의사정족수에 달하였으므로 1차 본회의 개의를 시작하겠습니다. 성원이 되었\n",
            "   7  조조례 개정조례에 대하여 보고 설명하여 주시기 바랍니다. 지역개발과장 윤영해입니다. 음성군간시장조례개정조례안에 대하여 보고 드리겠습니다. 제안사례에 대하여 보고 드리겠습니다. 제안사례에\n",
            "   8  입니다. 먼저 의사팀장으로부터 의회 관련 사항에 대한 보고가 있겠습니다. 의사팀장은 보고하여 주시기 바랍니다. 의사팀장 이은미입니다. 보고사항을 말씀드리겠습니다. 먼저, 제1차 본회의 이후 의안 접수사항입니다. 지난 11월 21일\n",
            "   9  합니다.합니다.합니다. 것 것 것 것 것 것 것 같은데 그것 때문에 음성읍청사 리모델링이 지연되고 있습니다. 그것 외에도 추진위원회하고 공사업체 관계가 원만하지 못한 부분이 더러 있는 것 같습니다. 그래서 그런 부분도 챙겨서 원만\n",
            "  10  의사일정 제8항, 2014년도 제2차 수시분 공유재산 관리 계획안, 의사일정 제9항, 음성군 재산세 도시지역분 적용대상지역 변경고시안을 계속해서 일괄 상정합니다. 재무과장께서는 나오셔서\n",
            "  11  제193회 음성군의회 임시회 회기결정의 건을 상정합니다. 제193회 음성군의회 음성군회 임시회 회기는 여러 의원님들께서 사전에 양해하여 주신대로 7월 7일 오늘 하루동안 하고자\n",
            "  12  함께 함께 함께 함께 함께 함께 함께 함께 함께 함께 함께 주시기 바랍니다. 대표 발의하신 손달섭 의원님께서는 나오셔서 특별위원회 구성안에 대하여 제안 설명을 하여 주시기 바랍니다. 손달섭 의원입니다.입니다. 손달섭\n",
            "  13  정정조례안, 의사일정 제6항, 음성군 지역아동센터 운영 및 지원에 관한 조례안을 일괄 상정합니다. 주민복지실장께서는 나오셔서 두 건의 안건에 대해서 일괄 제안설명해 주시기 바랍니다. 주민복지실장\n",
            "  14  보고 보고 보고가 있겠습니다. 보고사항을 말씀 말씀 말씀드리겠습니다. 보고사항을 말씀 말씀드리겠습니다. 보고사항을 말씀드리겠습니다.  '99년 1월 27일 완주군수로부터 완주군제증명등 수수료징수조례중\n",
            "  15  의사일정 제1항, 2018년도 주요업무 보고의 건을 상정합니다. 오늘은 건설교통과, 도시과, 산업개발과, 건축개발과, 건축허가과 순으로 보고를 받겠습니다. 그럼 먼저 건설교통과, 도시과, 산업개발과, 건축개발과,\n",
            "\n",
            "Target summaries:\n",
            "\n",
            "  Id  Target summary\n",
            "----  -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "   0  예산결산 특별위원회는 최관식 의원, 남궁유 의원, 김우식 의원, 고재협 의원, 김성채 의원, 진의장 의원, 이준구 의원, 김천봉 의원으로 구성함. 특별위원회는 제2차 정례회 기간 중 의사일정에 따라서 2002년도 예산과 2001년도 제3회 추가경제예산을 심의하고자 구성함. 해당 안건은 가결됨.\n",
            "   1  음성군 지방세입징수포상금 지급 조례 일부개정조례안은 2009년 11월 1일부터 전국 자치단체 간 징수촉탁제도 운용에 따라 수탁기관이 징수촉탁으로 징수 시 교부받은 금액의 10%를 유공공무원에게 지급하여 자동차세 징수촉탁제를 활성화하고, 결손처분 미수액의 10%를 포상금으로 지급하여 결손사후관리를 위한 세무공무원의 노력 강화로 세수확충을 하며, 조례 운영 상 나타난 일부 조문 및 용어의 미비점을 정비하기 위해 제안됨. 해당 안건은 가결됨.\n",
            "   2  권역별로 있는 중고등학교도 명문을 만들기 위해서 군에서도 지역과 균형을 맞출 것.\n",
            "   3  제208회 임시회 휴회의 건은 회기 중 증평, 진천, 괴산, 음성 국회의원 보궐선거로 휴회함.\n",
            "   4  제40회 청주시의회(임시회)의 회기는 2월 18일부터 2월 22일까지 5일간으로 가결됨.\n",
            "   5  안전총괄과 소관 주요업무 보고.\n",
            "   6  제214회 완주군의회 임시회 제1차 본회의 개의 선포.\n",
            "   7  음성군간이상수도관리조례개정조례안은 수도법의 개정으로 일정규모 미만인 시설을 소규모 급수시설로 분류함에 따라 기존의 음성군간이상수도관리조례를 개정 법령의 내용에 부합되게 개정하여 간이상수도 및 소규모급수시설을 보다 효율적으로 관리하기 위해 제안됨. 해당 안건은 가결됨.\n",
            "   8  제226회 완주군의회 제2차 정례회 제2차 본회의 개의 선포.\n",
            "   9  균형개발과 소관 주요 현안사업 보고.\n",
            "  10  2014년도 제2차 수시분 공유재산 관리계획안은 음성읍 청사를 신축하기 위해 공유재산 취득 계획을 일부 변경 추진하고자 하는 것으로 해당 안건은 가결됨. 음성군 재산세 도시지역분 적용대상지역 변경고시안은 음성군 도시지역 변경에 따라 재산세 도시지역분 적용대상지역을 변경하여 고시하고자 제안함.\n",
            "  11  제193회 음성군의회 임시회의 회기는 7월 7일 하루로 가결됨.\n",
            "  12  음성군 주요사업 현지확인 특별위원회 구성안은 음성군의 현안사업과 2010년도 행정사무감사 시 지적된 사업, 구제역 매몰지에 대한 현지확인, 사업의 추진사항을 점검하여 부실공사를 사전에 예방하고 사업예산이 필요한 곳에 적절히 쓰일 수 있도록 주요사업 현지확인 특별위원회를 구성하고자 함. 주요사업 현지확인 특별위원회 위원은 손수종 의원, 이한철 의원, 남궁유 의원, 조천희 의원, 손달섭 의원, 이대웅 의원, 김순옥 의원으로 구성하고자 함. 해당 결의안은 가결되었음.\n",
            "  13  음성군 저소득주민자녀 장학금 지급 조례 전부개정조례안은 저소득층 범위 완화, 장학금 지급대상자 확대 및 성적장학금 제외 등 장학금 지급 기준을 조정하고 알기 쉬운 법령 정비 기준에 따라서 불합리한 조문을 정비하기 위하여 본 조례를 전부개정 하려고 발의함. 해당 안건은 가결됨. 음성군 지역아동센터 운영 및 지원에 관한 조례안은 방과 후 돌봄이 필요한 지역사회 아동의 건전한 인격발달과 정서함양을 통하여 건강과 복지증진을 도모하기 위해 발의함.\n",
            "  14  제66회 완주군의회 임시회 제1차 본회의 개의 선포.\n",
            "  15  2018년도 주요업무 보고의 건은 건설교통과, 도시과, 산업개발과, 건축허가과 순으로 보고 진행함.\n"
          ]
        }
      ],
      "source": [
        "print(\n",
        "    tabulate(\n",
        "        zip(\n",
        "            range(len(summaries_after_tuning)),\n",
        "            summaries_after_tuning,\n",
        "        ),\n",
        "        headers=[\"Id\", \"Summary after\"],\n",
        "    )\n",
        ")\n",
        "print(\"\\nTarget summaries:\\n\")\n",
        "print(\n",
        "    tabulate(list(enumerate(test_samples[\"summary\"])), headers=[\"Id\", \"Target summary\"])\n",
        ")\n",
        "# print(\"\\nSource documents:\\n\")\n",
        "# print(tabulate(list(enumerate(test_samples[\"context\"])), headers=[\"Id\", \"context\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zV4eO9G1frHQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "sk",
      "language": "python",
      "name": "sk"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}