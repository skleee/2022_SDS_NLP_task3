{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Inference example\n",
    "- 모델 추론 예시입니다.\n",
    "- 모델 생성 관련 huggingface transformer 공식 문서: https://huggingface.co/docs/transformers/main_classes/text_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tako/anaconda3/envs/sk/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import PreTrainedTokenizerFast, BartForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(test_samples, model, tokenizer, encoder_max_length, num_beams, min_length, max_length):\n",
    "    inputs = tokenizer(\n",
    "        test_samples[\"context\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=encoder_max_length,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    input_ids = inputs.input_ids.to(model.device)\n",
    "    attention_mask = inputs.attention_mask.to(model.device)\n",
    "    outputs = model.generate(input_ids, attention_mask=attention_mask, num_beams=num_beams, min_length = min_length, max_length = max_length,)\n",
    "    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    return outputs, output_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = {'context': '다음은 의사일정 제3항 본회의 휴회의 건을 상정합니다. 상임위원회 등 의정활동을 위하여 2월 5일부터 2월 9일까지 5일간 본회의를 휴회하고자 하는데 의원 여러분 이의 있습니까? (“없습니다” 하는 의원 있음) 이의가 없으므로 가결되었음을 선포합니다. \\\n",
    "    이상으로 제247회 완주군의회 임시회 제1차 본회의를 마치겠습니다. 다음 제2차 본회의는 2월 10일 오전 10시에 개의하겠습니다. 의원 여러분 수고 많이 하셨습니다. 산회를 선포합니다.',\\\n",
    "    'summary': '2월 5일부터 2월 9일까지 5일간 본회의 휴회가 가결됨. 제2차 본회의는 2월 10일 오전 10시에 개의.'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BartTokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2월 5일부터 2월 9일까지 5일간 휴회가 가결됨. 제247회 완주군의회 임시회 제1차 본회의는 2월 10일 오전 10시에 개의. 제2차 본회의는 2월 10일 오전 10시에 개의. 산회를 선포.']\n"
     ]
    }
   ],
   "source": [
    "encoder_max_length = 512\n",
    "num_beams = 16\n",
    "min_length = 10\n",
    "max_length = 50\n",
    "\n",
    "model_pretrained = 'gogamza/kobart-summarization'\n",
    "\n",
    "# Download model and tokenizer\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(model_pretrained)\n",
    "\n",
    "'''\n",
    "Before training\n",
    "'''\n",
    "# Default pre-trained model is from https://github.com/seujung/KoBART-summarization \n",
    "# model = BartForConditionalGeneration.from_pretrained(model_pretrained)\n",
    "\n",
    "'''\n",
    "After training\n",
    "'''\n",
    "checkpoint_path = None # checkpoint path를 명시해주세요\n",
    "model = BartForConditionalGeneration.from_pretrained(checkpoint_path)\n",
    "\n",
    "predicted_summary = generate_summary(test_samples, model, tokenizer, encoder_max_length, num_beams, min_length, max_length)[1]\n",
    "print(predicted_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sk",
   "language": "python",
   "name": "sk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
